{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finetuning LLM for SAT Reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97NYN3e_6BcS"
      },
      "source": [
        "## 1. Install and import necessary libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO59tP-Bvion",
        "outputId": "202dacf6-1151-4057-d804-015e2d4f5a0a"
      },
      "outputs": [],
      "source": [
        "# !pip install -q -U bitsandbytes\n",
        "# !pip install -q -U datasets\n",
        "# !pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "# !pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "# !pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "# !pip install -q -U loralib\n",
        "# !pip install -q -U einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1g4cs-qYwjtO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tiviluson/miniconda3/envs/deeplearning/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL3aZuZr6LRp"
      },
      "source": [
        "## 2. Load pre-trained LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kFK18GDxMaW"
      },
      "outputs": [],
      "source": [
        "from transformers.utils.quantization_config import BitsAndBytesConfig\n",
        "\n",
        "MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "# MODEL_NAME = \"Qwen/Qwen3-4B\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    \n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414,
          "referenced_widgets": [
            "6abe1b81c4de491da5ea2c6f634efb23",
            "384a9fc5f4864f35b5a3ff4e79cb1a63",
            "c1c5f226c7b74f59bc2a3921cae04942",
            "09af949d22f0452c975cd62c89f76081",
            "35018d3b29e44833900ce8a12b846ac6",
            "23eede34912c440e80f4f7499584eb21",
            "e8e9a5df7a124dae833c36dbc48903d2",
            "c8e032c9c1bc446ba2593a293a1b677c",
            "43cd862c77d34fed8b69ab2538a17804",
            "e93e52e4cb614b0797b205200fa2a49b",
            "9404b36393064f7590998f9d581b559a",
            "aeb1c60cd19b4f06a883f220ab96d91f",
            "e1e0dbc30e2647b0a292b58fc6a71df3",
            "927d64bddb904f19957e54a93d0c19c4",
            "7155a0f7974b4d7f8320b31a550f1d44",
            "98c55c7897e14151a3572213f50d73e2",
            "fc203ffc1e46468cb527b067b4e74ecd",
            "add3c056f42a483d82d0a65fe0e18b2a",
            "5587cf5cef334d7d8e0f65b25efc66f0",
            "ed99799943f341cf942f29c3a3b6548e",
            "ed1e08bad6bc41029d7d2df69bf04398",
            "5d3bacd68db346e8858f24ee2a184128",
            "a03ebb1614814a46a6420c76715b1b82",
            "9855862689694f869e4112aec21522e9",
            "e7400616a60441d484b4981ec2cf10e8",
            "b125bdae8a30455dbfbf55c015fe3b8a",
            "9f65353e8b8b4120bd2bcb5b3b06d031",
            "7b25d945250e4c36a355a87783d71446",
            "3ff234a90d8c465a822567c3bc5d0b91",
            "6c33c895e5ca4ab1a01f8b8d697a7f0b",
            "c83973f019534568834367797ae9b9ec",
            "75cb94e6c96e43839736ec0891de189a",
            "3f6f2e2bc8aa408bb70370f2bbae1305",
            "3060dbfc567f419da3659aef56ea01d2",
            "f2272ea1c70b4f679db18564fcd9cf0b",
            "c3537858fbf2432fb4233660ae3cf473",
            "435c8186f1f14ad1ad773580c1fddb5e",
            "e35cbba17f144dfb940217a5415a0031",
            "e61b6aec69654ee9bf845ec79c6259ab",
            "9744605e38244b16b2a37714908ca02f",
            "db27042cb6574d0a9cb4a8a2613da7b0",
            "e17a2332f3284668990cfdf3f9c8ec75",
            "b525a1fa82bd4e589450c6994266d293",
            "c51649878ab14382a3c44f3b3398f3e3",
            "bcbc7cc0d577454d8629c1960ba6cdfd",
            "c9fc835ef2094721aaec3a844c88c998",
            "afcba9881fd5466f85620d8ee5dedfeb",
            "fb5a55058d564fb18ada5509a1b3ca2d",
            "ad01da3f35b64321be81883f2c97286f",
            "22c76b133fe844ed838445ed7cb1f827",
            "90777168817640b48a3084ea2bc423ca",
            "f0cc63548c3d412a971d47aae59440ef",
            "60a0432c24a243e391a38ff61b714120",
            "325ba8666f504335a36ef9a91838e88c",
            "e115c0667a2c445ab65b16a4f38bd8f4",
            "ef8c4198e92f41c294297349b9a82b58",
            "02d8fb58beaa4ca4a2598ef3543762df",
            "5af8494cb1724593864ee0aa4633a674",
            "abcd79cf38224fb48f4d26c6c3a298c9",
            "a9383793c8314e7ead63f84dc6fe1f9f",
            "5798421a0533435aaa7f2de0bb5e7d14",
            "080472662db946a5bd667b3520e0cb26",
            "5d44e2d2de8f40b1bd15348805d6638a",
            "57553c3f2dd949b1b7e280d192d7012b",
            "98c2bd9ac28c4134922a9960673d2787",
            "09e4bfab03f0418491ac9d98b533ede8",
            "87d6b994470e4d3c96308e9e64125bdd",
            "39cd48f27b624a3bbf462d7084694daf",
            "0337ef0f697847428055499bb1816882",
            "0c917ed275f2464d90ce210fc5ae5589",
            "dfd583d5e301470fa9598d59bdc216a8",
            "aa877365d56b48fc91f30f523f30a6ca",
            "14c8472c50f9451781a9f50b52581791",
            "c404b05899104b5380a6efaf069f638d",
            "d843e4f5a7934b09bddf1ae6427d433a",
            "f8843aaad1654a5c87aec8788dd3178b",
            "5778a2b89be94a39aac59fd3db7f77ce",
            "b72df54a1c424715a802d01ebf224053",
            "cbd8301c0b9e47dba8680a73b52c849b",
            "d07383055fd64c57b6caa209d2ad74ca",
            "683e243ec4f749e3a3060db7e28c27e4",
            "38f9d09e9dec42eab7e89265783f707e",
            "f4e69a606a684948940e9cc44b24b00d",
            "c115b67bf75e43069c5c6831b0ae7148",
            "876f8027f61a4b4faf2b767f96bddc07",
            "1a2d9a2b8a5d43e9894c679ff280e4b5",
            "ebd96abb117e421593563f10fc2612a3",
            "13bc9121cedc471ab1b9b78af6923dce"
          ]
        },
        "id": "cW56RiCyHp09",
        "outputId": "ef72e941-2ac2-4990-e749-eb014f3e73cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading tokenizer...\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"cuda:0\",\n",
        "    offload_state_dict=True,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "print(\"Loading tokenizer...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZs0QUBIHp09",
        "outputId": "0fb004b2-107c-49a5-ad3a-1cbb041dad06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 2048)\n",
              "    (layers): ModuleList(\n",
              "      (0-15): 16 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TJEtVaVXHp09"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.special_tokens_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g3IyFZsPP3xC"
      },
      "outputs": [],
      "source": [
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 2048)\n",
              "    (layers): ModuleList(\n",
              "      (0-15): 16 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "leNliYBZ0IqT"
      },
      "outputs": [],
      "source": [
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039\n"
          ]
        }
      ],
      "source": [
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Free memory: 12.01 GB\n",
            "Total memory: 15.57 GB\n"
          ]
        }
      ],
      "source": [
        "mem_free, mem_total = torch.cuda.mem_get_info()\n",
        "print(f\"Free memory: {mem_free / 1024**3:.2f} GB\")\n",
        "print(f\"Total memory: {mem_total / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 2048)\n",
              "        (layers): ModuleList(\n",
              "          (0-15): 16 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY2I1hXZa4Qt"
      },
      "source": [
        "## 3. Test pre-trained model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GhX68KkaP3xD"
      },
      "outputs": [],
      "source": [
        "from transformers.generation.configuration_utils import GenerationConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "B56-xXB6P3xE"
      },
      "outputs": [],
      "source": [
        "# Llama-3's official system prompt structure\n",
        "LLAMA3_SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant developed by Meta. Respond safely and accurately.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "C5aDJcvm0PDj"
      },
      "outputs": [],
      "source": [
        "# Test pretrained model performance\n",
        "prompt = [\n",
        "    {\"role\": \"system\", \"content\": LLAMA3_SYSTEM_PROMPT},\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Analyze the given passage and question. Choose the best answer from the options below.\n",
        "\n",
        "### Passage:\n",
        "[This passage is adapted from George Eliot, Silas Marner. Originally published in 1861. Silas was a weaver and a notorious miser, but then the gold he had hoarded was stolen. Shortly after, Silas adopted a young child, Eppie, the daughter of an impoverished woman who had died suddenly.\n",
        "\n",
        "    Unlike the gold which needed nothing, and must\n",
        "be worshipped in close-locked solitude—which was\n",
        "hidden away from the daylight, was deaf to the song\n",
        "of birds, and started to no human tones—Eppie was a\n",
        "creature of endless claims and ever-growing desires,\n",
        "seeking and loving sunshine, and living sounds, and\n",
        "living movements; making trial of everything, with\n",
        "trust in new joy, and stirring the human kindness in\n",
        "all eyes that looked on her. The gold had kept his\n",
        "thoughts in an ever-repeated circle, leading to\n",
        "nothing beyond itself; but Eppie was an object\n",
        "compacted of changes and hopes that forced his\n",
        "thoughts onward, and carried them far away from\n",
        "their old eager pacing towards the same blank\n",
        "limit—carried them away to the new things that\n",
        "would come with the coming years, when Eppie\n",
        "would have learned to understand how her father\n",
        "Silas cared for her; and made him look for images of\n",
        "that time in the ties and charities that bound together\n",
        "the families of his neighbors. The gold had asked that\n",
        "he should sit weaving longer and longer, deafened\n",
        "and blinded more and more to all things except the\n",
        "monotony of his loom and the repetition of his web;\n",
        "but Eppie called him away from his weaving, and\n",
        "made him think all its pauses a holiday, reawakening\n",
        "his senses with her fresh life, even to the old\n",
        "winter-flies that came crawling forth in the early\n",
        "spring sunshine, and warming him into joy because\n",
        "she had joy.\n",
        "    And when the sunshine grew strong and lasting,\n",
        "so that the buttercups were thick in the meadows,\n",
        "Silas might be seen in the sunny mid-day, or in the\n",
        "late afternoon when the shadows were lengthening\n",
        "under the hedgerows, strolling out with uncovered\n",
        "head to carry Eppie beyond the Stone-pits to where\n",
        "the flowers grew, till they reached some favorite bank\n",
        "where he could sit down, while Eppie toddled to\n",
        "pluck the flowers, and make remarks to the winged\n",
        "things that murmured happily above the bright\n",
        "petals, calling “Dad-dad’s” attention continually by\n",
        "bringing him the flowers. Then she would turn her\n",
        "ear to some sudden bird-note, and Silas learned to\n",
        "please her by making signs of hushed stillness, that\n",
        "they might listen for the note to come again: so that\n",
        "when it came, she set up her small back and laughed\n",
        "with gurgling triumph. Sitting on the banks in this\n",
        "way, Silas began to look for the once familiar herbs\n",
        "again; and as the leaves, with their unchanged outline\n",
        "and markings, lay on his palm, there was a sense of\n",
        "crowding remembrances from which he turned away\n",
        "timidly, taking refuge in Eppie’s little world, that lay\n",
        "lightly on his enfeebled spirit.\n",
        "    As the child’s mind was growing into knowledge,\n",
        "his mind was growing into memory: as her life\n",
        "unfolded, his soul, long stupefied in a cold narrow\n",
        "prison, was unfolding too, and trembling gradually\n",
        "into full consciousness.\n",
        "    It was an influence which must gather force with\n",
        "every new year: the tones that stirred Silas’ heart\n",
        "grew articulate, and called for more distinct answers;\n",
        "shapes and sounds grew clearer for Eppie’s eyes and\n",
        "ears, and there was more that “Dad-dad” was\n",
        "imperatively required to notice and account for.\n",
        "Also, by the time Eppie was three years old, she\n",
        "developed a fine capacity for mischief, and for\n",
        "devising ingenious ways of being troublesome, which\n",
        "found much exercise, not only for Silas’ patience, but\n",
        "for his watchfulness and penetration. Sorely was poor\n",
        "Silas puzzled on such occasions by the incompatible\n",
        "demands of love.]\n",
        "\n",
        "### Question:\n",
        "Which statement best describes a technique the narrator uses to represent Silas's character before he adopted Eppie?\n",
        "\n",
        "### Choices:\n",
        "A) The narrator emphasizes Silas's former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
        "B) The narrator underscores Silas's former greed by describing his gold as seeming to reproduce on its own.\n",
        "C) The narrator hints at Silas's former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
        "D) The narrator demonstrates Silas's former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
        "\n",
        "Respond ONLY with the letter and full text of the correct answer choice.\"\"\",\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 04 May 2025\n",
            "\n",
            "You are a helpful AI assistant developed by Meta. Respond safely and accurately.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Analyze the given passage and question. Choose the best answer from the options below.\n",
            "\n",
            "### Passage:\n",
            "[This passage is adapted from George Eliot, Silas Marner. Originally published in 1861. Silas was a weaver and a notorious miser, but then the gold he had hoarded was stolen. Shortly after, Silas adopted a young child, Eppie, the daughter of an impoverished woman who had died suddenly.\n",
            "\n",
            "    Unlike the gold which needed nothing, and must\n",
            "be worshipped in close-locked solitude—which was\n",
            "hidden away from the daylight, was deaf to the song\n",
            "of birds, and started to no human tones—Eppie was a\n",
            "creature of endless claims and ever-growing desires,\n",
            "seeking and loving sunshine, and living sounds, and\n",
            "living movements; making trial of everything, with\n",
            "trust in new joy, and stirring the human kindness in\n",
            "all eyes that looked on her. The gold had kept his\n",
            "thoughts in an ever-repeated circle, leading to\n",
            "nothing beyond itself; but Eppie was an object\n",
            "compacted of changes and hopes that forced his\n",
            "thoughts onward, and carried them far away from\n",
            "their old eager pacing towards the same blank\n",
            "limit—carried them away to the new things that\n",
            "would come with the coming years, when Eppie\n",
            "would have learned to understand how her father\n",
            "Silas cared for her; and made him look for images of\n",
            "that time in the ties and charities that bound together\n",
            "the families of his neighbors. The gold had asked that\n",
            "he should sit weaving longer and longer, deafened\n",
            "and blinded more and more to all things except the\n",
            "monotony of his loom and the repetition of his web;\n",
            "but Eppie called him away from his weaving, and\n",
            "made him think all its pauses a holiday, reawakening\n",
            "his senses with her fresh life, even to the old\n",
            "winter-flies that came crawling forth in the early\n",
            "spring sunshine, and warming him into joy because\n",
            "she had joy.\n",
            "    And when the sunshine grew strong and lasting,\n",
            "so that the buttercups were thick in the meadows,\n",
            "Silas might be seen in the sunny mid-day, or in the\n",
            "late afternoon when the shadows were lengthening\n",
            "under the hedgerows, strolling out with uncovered\n",
            "head to carry Eppie beyond the Stone-pits to where\n",
            "the flowers grew, till they reached some favorite bank\n",
            "where he could sit down, while Eppie toddled to\n",
            "pluck the flowers, and make remarks to the winged\n",
            "things that murmured happily above the bright\n",
            "petals, calling “Dad-dad’s” attention continually by\n",
            "bringing him the flowers. Then she would turn her\n",
            "ear to some sudden bird-note, and Silas learned to\n",
            "please her by making signs of hushed stillness, that\n",
            "they might listen for the note to come again: so that\n",
            "when it came, she set up her small back and laughed\n",
            "with gurgling triumph. Sitting on the banks in this\n",
            "way, Silas began to look for the once familiar herbs\n",
            "again; and as the leaves, with their unchanged outline\n",
            "and markings, lay on his palm, there was a sense of\n",
            "crowding remembrances from which he turned away\n",
            "timidly, taking refuge in Eppie’s little world, that lay\n",
            "lightly on his enfeebled spirit.\n",
            "    As the child’s mind was growing into knowledge,\n",
            "his mind was growing into memory: as her life\n",
            "unfolded, his soul, long stupefied in a cold narrow\n",
            "prison, was unfolding too, and trembling gradually\n",
            "into full consciousness.\n",
            "    It was an influence which must gather force with\n",
            "every new year: the tones that stirred Silas’ heart\n",
            "grew articulate, and called for more distinct answers;\n",
            "shapes and sounds grew clearer for Eppie’s eyes and\n",
            "ears, and there was more that “Dad-dad” was\n",
            "imperatively required to notice and account for.\n",
            "Also, by the time Eppie was three years old, she\n",
            "developed a fine capacity for mischief, and for\n",
            "devising ingenious ways of being troublesome, which\n",
            "found much exercise, not only for Silas’ patience, but\n",
            "for his watchfulness and penetration. Sorely was poor\n",
            "Silas puzzled on such occasions by the incompatible\n",
            "demands of love.]\n",
            "\n",
            "### Question:\n",
            "Which statement best describes a technique the narrator uses to represent Silas's character before he adopted Eppie?\n",
            "\n",
            "### Choices:\n",
            "A) The narrator emphasizes Silas's former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
            "B) The narrator underscores Silas's former greed by describing his gold as seeming to reproduce on its own.\n",
            "C) The narrator hints at Silas's former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
            "D) The narrator demonstrates Silas's former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
            "\n",
            "Respond ONLY with the letter and full text of the correct answer choice.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Apply chat template (text only)\n",
        "chat_text = tokenizer.apply_chat_template(\n",
        "    prompt, add_generation_prompt=True, tokenize=False\n",
        ")\n",
        "print(chat_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [128000, 128000, 128001], 'attention_mask': [1, 1, 1]}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\"<|begin_of_text|><|end_of_text|>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids: torch.Size([1, 1104])\n",
            "attention_mask: torch.Size([1, 1104])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Tokenize\n",
        "inputs = tokenizer(chat_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "for k, v in inputs.items():\n",
        "    print(f\"{k}: {v.shape}\")\n",
        "v.all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C8P1Qqcj0VIe",
        "outputId": "d668731b-180a-4d1e-c0a6-84dd63f08e45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 04 May 2025\n",
            "\n",
            "You are a helpful AI assistant developed by Meta. Respond safely and accurately.user\n",
            "\n",
            "Analyze the given passage and question. Choose the best answer from the options below.\n",
            "\n",
            "### Passage:\n",
            "[This passage is adapted from George Eliot, Silas Marner. Originally published in 1861. Silas was a weaver and a notorious miser, but then the gold he had hoarded was stolen. Shortly after, Silas adopted a young child, Eppie, the daughter of an impoverished woman who had died suddenly.\n",
            "\n",
            "    Unlike the gold which needed nothing, and must\n",
            "be worshipped in close-locked solitude—which was\n",
            "hidden away from the daylight, was deaf to the song\n",
            "of birds, and started to no human tones—Eppie was a\n",
            "creature of endless claims and ever-growing desires,\n",
            "seeking and loving sunshine, and living sounds, and\n",
            "living movements; making trial of everything, with\n",
            "trust in new joy, and stirring the human kindness in\n",
            "all eyes that looked on her. The gold had kept his\n",
            "thoughts in an ever-repeated circle, leading to\n",
            "nothing beyond itself; but Eppie was an object\n",
            "compacted of changes and hopes that forced his\n",
            "thoughts onward, and carried them far away from\n",
            "their old eager pacing towards the same blank\n",
            "limit—carried them away to the new things that\n",
            "would come with the coming years, when Eppie\n",
            "would have learned to understand how her father\n",
            "Silas cared for her; and made him look for images of\n",
            "that time in the ties and charities that bound together\n",
            "the families of his neighbors. The gold had asked that\n",
            "he should sit weaving longer and longer, deafened\n",
            "and blinded more and more to all things except the\n",
            "monotony of his loom and the repetition of his web;\n",
            "but Eppie called him away from his weaving, and\n",
            "made him think all its pauses a holiday, reawakening\n",
            "his senses with her fresh life, even to the old\n",
            "winter-flies that came crawling forth in the early\n",
            "spring sunshine, and warming him into joy because\n",
            "she had joy.\n",
            "    And when the sunshine grew strong and lasting,\n",
            "so that the buttercups were thick in the meadows,\n",
            "Silas might be seen in the sunny mid-day, or in the\n",
            "late afternoon when the shadows were lengthening\n",
            "under the hedgerows, strolling out with uncovered\n",
            "head to carry Eppie beyond the Stone-pits to where\n",
            "the flowers grew, till they reached some favorite bank\n",
            "where he could sit down, while Eppie toddled to\n",
            "pluck the flowers, and make remarks to the winged\n",
            "things that murmured happily above the bright\n",
            "petals, calling “Dad-dad’s” attention continually by\n",
            "bringing him the flowers. Then she would turn her\n",
            "ear to some sudden bird-note, and Silas learned to\n",
            "please her by making signs of hushed stillness, that\n",
            "they might listen for the note to come again: so that\n",
            "when it came, she set up her small back and laughed\n",
            "with gurgling triumph. Sitting on the banks in this\n",
            "way, Silas began to look for the once familiar herbs\n",
            "again; and as the leaves, with their unchanged outline\n",
            "and markings, lay on his palm, there was a sense of\n",
            "crowding remembrances from which he turned away\n",
            "timidly, taking refuge in Eppie’s little world, that lay\n",
            "lightly on his enfeebled spirit.\n",
            "    As the child’s mind was growing into knowledge,\n",
            "his mind was growing into memory: as her life\n",
            "unfolded, his soul, long stupefied in a cold narrow\n",
            "prison, was unfolding too, and trembling gradually\n",
            "into full consciousness.\n",
            "    It was an influence which must gather force with\n",
            "every new year: the tones that stirred Silas’ heart\n",
            "grew articulate, and called for more distinct answers;\n",
            "shapes and sounds grew clearer for Eppie’s eyes and\n",
            "ears, and there was more that “Dad-dad” was\n",
            "imperatively required to notice and account for.\n",
            "Also, by the time Eppie was three years old, she\n",
            "developed a fine capacity for mischief, and for\n",
            "devising ingenious ways of being troublesome, which\n",
            "found much exercise, not only for Silas’ patience, but\n",
            "for his watchfulness and penetration. Sorely was poor\n",
            "Silas puzzled on such occasions by the incompatible\n",
            "demands of love.]\n",
            "\n",
            "### Question:\n",
            "Which statement best describes a technique the narrator uses to represent Silas's character before he adopted Eppie?\n",
            "\n",
            "### Choices:\n",
            "A) The narrator emphasizes Silas's former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
            "B) The narrator underscores Silas's former greed by describing his gold as seeming to reproduce on its own.\n",
            "C) The narrator hints at Silas's former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
            "D) The narrator demonstrates Silas's former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
            "\n",
            "Respond ONLY with the letter and full text of the correct answer choice.assistant\n",
            "\n",
            "A \n",
            "The narrator highlights Silas's obsessive nature through descriptions like \"making trials\" (describing himself), seeking constant change (\"ever-growing\") without fulfillment, carrying burdensome thoughts forward (\"leading to nothing\"), repeating patterns over many years (\"re\n"
          ]
        }
      ],
      "source": [
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.01,\n",
        "    do_sample=True,\n",
        "    num_return_sequences=1,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    repetition_penalty=1.3,\n",
        ")\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        generation_config=generation_config,\n",
        "    )\n",
        "\n",
        "    # Decode output\n",
        "output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "# print\n",
        "if \"<|assistant|>\" in output_text:\n",
        "    print(output_text.split(\"<|assistant|>\")[-1].strip())\n",
        "else:\n",
        "    print(output_text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK7lUW10a9d5"
      },
      "source": [
        "## 4. Fine-tuning LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKzaGrv2a_fg"
      },
      "source": [
        "### 4.1. Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets.dataset_dict import DatasetDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xwPC_aBB6VXm"
      },
      "outputs": [],
      "source": [
        "data: DatasetDict = load_dataset(\"emozilla/sat-reading\")  # type: ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImH26GW96vbB",
        "outputId": "f5dd5c46-8e30-41db-d991-de8e07751139"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 298\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 39\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 38\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnrdD8pZoOPx",
        "outputId": "8a7c9178-f769-40bd-a4e1-59097d36f35d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datasets.dataset_dict.DatasetDict"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hVunfNU68i0",
        "outputId": "9042babb-ea0f-431e-f246-e643e2b26efa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'answer', 'requires_line', 'id'],\n",
              "    num_rows: 298\n",
              "})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6Daio0eONzd",
        "outputId": "108cbe95-8a66-4372-c8e8-1d31d86a86c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAT READING COMPREHENSION TEST\n",
            "\n",
            "This passage is adapted from George Eliot, Silas Marner.\n",
            "Originally published in 1861. Silas was a weaver and a\n",
            "notorious miser, but then the gold he had hoarded was\n",
            "stolen. Shortly after, Silas adopted a young child, Eppie, the\n",
            "daughter of an impoverished woman who had died\n",
            "suddenly.\n",
            "\n",
            "    Unlike the gold which needed nothing, and must\n",
            "be worshipped in close-locked solitude—which was\n",
            "hidden away from the daylight, was deaf to the song\n",
            "of birds, and started to no human tones—Eppie was a\n",
            "creature of endless claims and ever-growing desires,\n",
            "seeking and loving sunshine, and living sounds, and\n",
            "living movements; making trial of everything, with\n",
            "trust in new joy, and stirring the human kindness in\n",
            "all eyes that looked on her. The gold had kept his\n",
            "thoughts in an ever-repeated circle, leading to\n",
            "nothing beyond itself; but Eppie was an object\n",
            "compacted of changes and hopes that forced his\n",
            "thoughts onward, and carried them far away from\n",
            "their old eager pacing towards the same blank\n",
            "limit—carried them away to the new things that\n",
            "would come with the coming years, when Eppie\n",
            "would have learned to understand how her father\n",
            "Silas cared for her; and made him look for images of\n",
            "that time in the ties and charities that bound together\n",
            "the families of his neighbors. The gold had asked that\n",
            "he should sit weaving longer and longer, deafened\n",
            "and blinded more and more to all things except the\n",
            "monotony of his loom and the repetition of his web;\n",
            "but Eppie called him away from his weaving, and\n",
            "made him think all its pauses a holiday, reawakening\n",
            "his senses with her fresh life, even to the old\n",
            "winter-flies that came crawling forth in the early\n",
            "spring sunshine, and warming him into joy because\n",
            "she had joy.\n",
            "    And when the sunshine grew strong and lasting,\n",
            "so that the buttercups were thick in the meadows,\n",
            "Silas might be seen in the sunny mid-day, or in the\n",
            "late afternoon when the shadows were lengthening\n",
            "under the hedgerows, strolling out with uncovered\n",
            "head to carry Eppie beyond the Stone-pits to where\n",
            "the flowers grew, till they reached some favorite bank\n",
            "where he could sit down, while Eppie toddled to\n",
            "pluck the flowers, and make remarks to the winged\n",
            "things that murmured happily above the bright\n",
            "petals, calling “Dad-dad’s” attention continually by\n",
            "bringing him the flowers. Then she would turn her\n",
            "ear to some sudden bird-note, and Silas learned to\n",
            "please her by making signs of hushed stillness, that\n",
            "they might listen for the note to come again: so that\n",
            "when it came, she set up her small back and laughed\n",
            "with gurgling triumph. Sitting on the banks in this\n",
            "way, Silas began to look for the once familiar herbs\n",
            "again; and as the leaves, with their unchanged outline\n",
            "and markings, lay on his palm, there was a sense of\n",
            "crowding remembrances from which he turned away\n",
            "timidly, taking refuge in Eppie’s little world, that lay\n",
            "lightly on his enfeebled spirit.\n",
            "    As the child’s mind was growing into knowledge,\n",
            "his mind was growing into memory: as her life\n",
            "unfolded, his soul, long stupefied in a cold narrow\n",
            "prison, was unfolding too, and trembling gradually\n",
            "into full consciousness.\n",
            "    It was an influence which must gather force with\n",
            "every new year: the tones that stirred Silas’ heart\n",
            "grew articulate, and called for more distinct answers;\n",
            "shapes and sounds grew clearer for Eppie’s eyes and\n",
            "ears, and there was more that “Dad-dad” was\n",
            "imperatively required to notice and account for.\n",
            "Also, by the time Eppie was three years old, she\n",
            "developed a fine capacity for mischief, and for\n",
            "devising ingenious ways of being troublesome, which\n",
            "found much exercise, not only for Silas’ patience, but\n",
            "for his watchfulness and penetration. Sorely was poor\n",
            "Silas puzzled on such occasions by the incompatible\n",
            "demands of love.\n",
            "\n",
            "\n",
            "\n",
            "Question 4:\n",
            "The narrator uses the phrase “making trial of everything” (line 7) to present Eppie as\n",
            "A) friendly.\n",
            "B) curious.\n",
            "C) disobedient.\n",
            "D) judgmental.\n",
            "\n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "print(data[\"train\"][\"text\"][4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0UKWAUSMAsH",
        "outputId": "838e3d17-8947-4f49-826e-686a360460fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "B\n"
          ]
        }
      ],
      "source": [
        "print(data[\"train\"][\"answer\"][4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IRZPr4jHP3xG"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def extract_sections(text):\n",
        "    \"\"\"Parse raw SAT text into structured sections\"\"\"\n",
        "    sections = {\"passage\": \"\", \"question\": \"\", \"choices\": [], \"answer_letter\": \"\"}\n",
        "\n",
        "    # Tách phần answer\n",
        "    match = re.search(r\"Answer:\\s*([A-E])\", text, re.IGNORECASE)\n",
        "    sections[\"answer_letter\"] = match.group(1) if match else \"\"\n",
        "\n",
        "    # Tách các phần chính\n",
        "    # Greedy matching with *\n",
        "    match = re.search(\n",
        "        r\"SAT READING COMPREHENSION TEST(.*)Answer:\", text, re.DOTALL | re.IGNORECASE\n",
        "    )\n",
        "    content = match.group(1).strip() if match else \"\"\n",
        "    blocks = [b.strip() for b in re.split(r\"\\n\\n\", content) if b.strip()]\n",
        "    sections[\"passage\"] = \"\\n\".join(blocks[0:2])\n",
        "    question_block = blocks[2].splitlines()\n",
        "    sections[\"question\"] = question_block[1]\n",
        "    sections[\"choices\"] = question_block[2:]\n",
        "\n",
        "    return sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'passage': 'This passage is adapted from George Eliot, Silas Marner.\\nOriginally published in 1861. Silas was a weaver and a\\nnotorious miser, but then the gold he had hoarded was\\nstolen. Shortly after, Silas adopted a young child, Eppie, the\\ndaughter of an impoverished woman who had died\\nsuddenly.\\nUnlike the gold which needed nothing, and must\\nbe worshipped in close-locked solitude—which was\\nhidden away from the daylight, was deaf to the song\\nof birds, and started to no human tones—Eppie was a\\ncreature of endless claims and ever-growing desires,\\nseeking and loving sunshine, and living sounds, and\\nliving movements; making trial of everything, with\\ntrust in new joy, and stirring the human kindness in\\nall eyes that looked on her. The gold had kept his\\nthoughts in an ever-repeated circle, leading to\\nnothing beyond itself; but Eppie was an object\\ncompacted of changes and hopes that forced his\\nthoughts onward, and carried them far away from\\ntheir old eager pacing towards the same blank\\nlimit—carried them away to the new things that\\nwould come with the coming years, when Eppie\\nwould have learned to understand how her father\\nSilas cared for her; and made him look for images of\\nthat time in the ties and charities that bound together\\nthe families of his neighbors. The gold had asked that\\nhe should sit weaving longer and longer, deafened\\nand blinded more and more to all things except the\\nmonotony of his loom and the repetition of his web;\\nbut Eppie called him away from his weaving, and\\nmade him think all its pauses a holiday, reawakening\\nhis senses with her fresh life, even to the old\\nwinter-flies that came crawling forth in the early\\nspring sunshine, and warming him into joy because\\nshe had joy.\\n    And when the sunshine grew strong and lasting,\\nso that the buttercups were thick in the meadows,\\nSilas might be seen in the sunny mid-day, or in the\\nlate afternoon when the shadows were lengthening\\nunder the hedgerows, strolling out with uncovered\\nhead to carry Eppie beyond the Stone-pits to where\\nthe flowers grew, till they reached some favorite bank\\nwhere he could sit down, while Eppie toddled to\\npluck the flowers, and make remarks to the winged\\nthings that murmured happily above the bright\\npetals, calling “Dad-dad’s” attention continually by\\nbringing him the flowers. Then she would turn her\\near to some sudden bird-note, and Silas learned to\\nplease her by making signs of hushed stillness, that\\nthey might listen for the note to come again: so that\\nwhen it came, she set up her small back and laughed\\nwith gurgling triumph. Sitting on the banks in this\\nway, Silas began to look for the once familiar herbs\\nagain; and as the leaves, with their unchanged outline\\nand markings, lay on his palm, there was a sense of\\ncrowding remembrances from which he turned away\\ntimidly, taking refuge in Eppie’s little world, that lay\\nlightly on his enfeebled spirit.\\n    As the child’s mind was growing into knowledge,\\nhis mind was growing into memory: as her life\\nunfolded, his soul, long stupefied in a cold narrow\\nprison, was unfolding too, and trembling gradually\\ninto full consciousness.\\n    It was an influence which must gather force with\\nevery new year: the tones that stirred Silas’ heart\\ngrew articulate, and called for more distinct answers;\\nshapes and sounds grew clearer for Eppie’s eyes and\\nears, and there was more that “Dad-dad” was\\nimperatively required to notice and account for.\\nAlso, by the time Eppie was three years old, she\\ndeveloped a fine capacity for mischief, and for\\ndevising ingenious ways of being troublesome, which\\nfound much exercise, not only for Silas’ patience, but\\nfor his watchfulness and penetration. Sorely was poor\\nSilas puzzled on such occasions by the incompatible\\ndemands of love.',\n",
              " 'question': 'The narrator uses the phrase “making trial of everything” (line 7) to present Eppie as',\n",
              " 'choices': ['A) friendly.',\n",
              "  'B) curious.',\n",
              "  'C) disobedient.',\n",
              "  'D) judgmental.'],\n",
              " 'answer_letter': ''}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extract_sections(data[\"train\"][\"text\"][4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "lcnc_sHKP3xH"
      },
      "outputs": [],
      "source": [
        "def map_answer(text, letter):\n",
        "    \"\"\"Match answer letter with full choice text\"\"\"\n",
        "    sections = extract_sections(text)\n",
        "    for choice in sections[\"choices\"]:\n",
        "        if choice.startswith(f\"{letter})\"):\n",
        "            return choice\n",
        "    return letter  # Fallback if not found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "rMxfJFHEv8J7"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(text, answer_letter):\n",
        "    sections = extract_sections(text)\n",
        "\n",
        "    choices_text = \"\\n\".join(sections[\"choices\"])\n",
        "\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": LLAMA3_SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Read the passage and answer the question.\n",
        "\n",
        "### Passage:\n",
        "{sections['passage']}\n",
        "\n",
        "### Question:\n",
        "{sections['question']}\n",
        "\n",
        "### Choices:\n",
        "{choices_text}\n",
        "\n",
        "Respond with ONLY the letter and full text of the correct answer.\"\"\",\n",
        "        },\n",
        "        {\"role\": \"assistant\", \"content\": map_answer(text, answer_letter)},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "z-GbfsEOZ-T_"
      },
      "outputs": [],
      "source": [
        "def generate_and_tokenize_prompt(user_input, answer):\n",
        "    try:\n",
        "        full_prompt = generate_prompt(user_input, answer)\n",
        "\n",
        "        prompt_str = tokenizer.apply_chat_template(\n",
        "            full_prompt, tokenize=False, add_generation_prompt=False\n",
        "        )\n",
        "        tokenized = tokenizer(\n",
        "            prompt_str,\n",
        "            # padding=\"max_length\",\n",
        "            # truncation=True,\n",
        "            # max_length=1500,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        input_ids = tokenized[\"input_ids\"][0]\n",
        "        # labels = input_ids.clone()\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": tokenized[\"attention_mask\"][0],\n",
        "            # \"labels\": labels,\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing sample: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "DzkPgPviP3xH",
        "outputId": "49907b7b-acd3-41ed-e1ea-7ff4bcb55089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Generated Prompt ===\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 04 May 2025\n",
            "\n",
            "You are a helpful AI assistant developed by Meta. Respond safely and accurately.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Read the passage and answer the question.\n",
            "\n",
            "### Passage:\n",
            "This passage is adapted from George Eliot, Silas Marner.\n",
            "Originally published in 1861. Silas was a weaver and a\n",
            "notorious miser, but then the gold he had hoarded was\n",
            "stolen. Shortly after, Silas adopted a young child, Eppie, the\n",
            "daughter of an impoverished woman who had died\n",
            "suddenly.\n",
            "Unlike the gold which needed nothing, and must\n",
            "be worshipped in close-locked solitude—which was\n",
            "hidden away from the daylight, was deaf to the song\n",
            "of birds, and started to no human tones—Eppie was a\n",
            "creature of endless claims and ever-growing desires,\n",
            "seeking and loving sunshine, and living sounds, and\n",
            "living movements; making trial of everything, with\n",
            "trust in new joy, and stirring the human kindness in\n",
            "all eyes that looked on her. The gold had kept his\n",
            "thoughts in an ever-repeated circle, leading to\n",
            "nothing beyond itself; but Eppie was an object\n",
            "compacted of changes and hopes that forced his\n",
            "thoughts onward, and carried them far away from\n",
            "their old eager pacing towards the same blank\n",
            "limit—carried them away to the new things that\n",
            "would come with the coming years, when Eppie\n",
            "would have learned to understand how her father\n",
            "Silas cared for her; and made him look for images of\n",
            "that time in the ties and charities that bound together\n",
            "the families of his neighbors. The gold had asked that\n",
            "he should sit weaving longer and longer, deafened\n",
            "and blinded more and more to all things except the\n",
            "monotony of his loom and the repetition of his web;\n",
            "but Eppie called him away from his weaving, and\n",
            "made him think all its pauses a holiday, reawakening\n",
            "his senses with her fresh life, even to the old\n",
            "winter-flies that came crawling forth in the early\n",
            "spring sunshine, and warming him into joy because\n",
            "she had joy.\n",
            "    And when the sunshine grew strong and lasting,\n",
            "so that the buttercups were thick in the meadows,\n",
            "Silas might be seen in the sunny mid-day, or in the\n",
            "late afternoon when the shadows were lengthening\n",
            "under the hedgerows, strolling out with uncovered\n",
            "head to carry Eppie beyond the Stone-pits to where\n",
            "the flowers grew, till they reached some favorite bank\n",
            "where he could sit down, while Eppie toddled to\n",
            "pluck the flowers, and make remarks to the winged\n",
            "things that murmured happily above the bright\n",
            "petals, calling “Dad-dad’s” attention continually by\n",
            "bringing him the flowers. Then she would turn her\n",
            "ear to some sudden bird-note, and Silas learned to\n",
            "please her by making signs of hushed stillness, that\n",
            "they might listen for the note to come again: so that\n",
            "when it came, she set up her small back and laughed\n",
            "with gurgling triumph. Sitting on the banks in this\n",
            "way, Silas began to look for the once familiar herbs\n",
            "again; and as the leaves, with their unchanged outline\n",
            "and markings, lay on his palm, there was a sense of\n",
            "crowding remembrances from which he turned away\n",
            "timidly, taking refuge in Eppie’s little world, that lay\n",
            "lightly on his enfeebled spirit.\n",
            "    As the child’s mind was growing into knowledge,\n",
            "his mind was growing into memory: as her life\n",
            "unfolded, his soul, long stupefied in a cold narrow\n",
            "prison, was unfolding too, and trembling gradually\n",
            "into full consciousness.\n",
            "    It was an influence which must gather force with\n",
            "every new year: the tones that stirred Silas’ heart\n",
            "grew articulate, and called for more distinct answers;\n",
            "shapes and sounds grew clearer for Eppie’s eyes and\n",
            "ears, and there was more that “Dad-dad” was\n",
            "imperatively required to notice and account for.\n",
            "Also, by the time Eppie was three years old, she\n",
            "developed a fine capacity for mischief, and for\n",
            "devising ingenious ways of being troublesome, which\n",
            "found much exercise, not only for Silas’ patience, but\n",
            "for his watchfulness and penetration. Sorely was poor\n",
            "Silas puzzled on such occasions by the incompatible\n",
            "demands of love.\n",
            "\n",
            "### Question:\n",
            "Which statement best describes a technique the narrator uses to represent Silas’s character before he adopted Eppie?\n",
            "\n",
            "### Choices:\n",
            "A) The narrator emphasizes Silas’s former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
            "B) The narrator underscores Silas’s former greed by describing his gold as seeming to reproduce on its own.\n",
            "C) The narrator hints at Silas’s former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
            "D) The narrator demonstrates Silas’s former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
            "\n",
            "Respond with ONLY the letter and full text of the correct answer.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "A) The narrator emphasizes Silas’s former obsession with wealth by depicting his gold as requiring certain behaviors on his part.<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "sample_text = data[\"train\"][\"text\"][0]\n",
        "sample_answer = data[\"train\"][\"answer\"][0]\n",
        "\n",
        "example_messages = generate_prompt(sample_text, sample_answer)\n",
        "prompt_text = tokenizer.apply_chat_template(\n",
        "    example_messages, tokenize=False, add_generation_prompt=False\n",
        ")\n",
        "print(\"=== Generated Prompt ===\")\n",
        "print(prompt_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54rwNsHCaTJL",
        "outputId": "b58fb398-e74c-4ef3-8d35-d2d2378b1d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Tokenized Sample ===\n",
            "Input IDs shape: torch.Size([1124])\n",
            "Sample decoded back:\n",
            "system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 04 May 2025\n",
            "\n",
            "You are a helpful AI assistant developed by Meta. Respond safely and accurately.user\n",
            "\n",
            "Read the passage and answer the question.\n",
            "\n",
            "### Passage:\n",
            "This passage is adapted from George Eliot, Silas Marner.\n",
            "Originally published in 1861. Silas was a weaver and a\n",
            "notorious miser, but then the gold he had hoarded was\n",
            "stolen. Shortly after, Silas adopted a young child, Eppie, the\n",
            "daughter of an impoverished woman who had died\n",
            "suddenly.\n",
            "Unlike the gold which needed nothing, and must\n",
            "be worshipped in close-locked solitude—which was\n",
            "hidden away from the daylight, was deaf to the song\n",
            "of birds, and started to no human tones—Eppie was a\n",
            "creature of endless claims and ever-growing desires,\n",
            "seeking and loving sunshine, and living sounds, and\n",
            "living movements; making trial of everything, with\n",
            "trust in new joy, and stirring the human kindness in\n",
            "all eyes that looked on her. The gold had kept his\n",
            "thoughts in an ever-repeated circle, leading to\n",
            "nothing beyond itself; but Eppie was an object\n",
            "compacted of changes and hopes that forced his\n",
            "thoughts onward, and carried them far away from\n",
            "their old eager pacing towards the same blank\n",
            "limit—carried them away to the new things that\n",
            "would come with the coming years, when Eppie\n",
            "would have learned to understand how her father\n",
            "Silas cared for her; and made him look for images of\n",
            "that time in the ties and charities that bound together\n",
            "the families of his neighbors. The gold had asked that\n",
            "he should sit weaving longer and longer, deafened\n",
            "and blinded more and more to all things except the\n",
            "monotony of his loom and the repetition of his web;\n",
            "but Eppie called him away from his weaving, and\n",
            "made him think all its pauses a holiday, reawakening\n",
            "his senses with her fresh life, even to the old\n",
            "winter-flies that came crawling forth in the early\n",
            "spring sunshine, and warming him into joy because\n",
            "she had joy.\n",
            "    And when the sunshine grew strong and lasting,\n",
            "so that the buttercups were thick in the meadows,\n",
            "Silas might be seen in the sunny mid-day, or in the\n",
            "late afternoon when the shadows were lengthening\n",
            "under the hedgerows, strolling out with uncovered\n",
            "head to carry Eppie beyond the Stone-pits to where\n",
            "the flowers grew, till they reached some favorite bank\n",
            "where he could sit down, while Eppie toddled to\n",
            "pluck the flowers, and make remarks to the winged\n",
            "things that murmured happily above the bright\n",
            "petals, calling “Dad-dad’s” attention continually by\n",
            "bringing him the flowers. Then she would turn her\n",
            "ear to some sudden bird-note, and Silas learned to\n",
            "please her by making signs of hushed stillness, that\n",
            "they might listen for the note to come again: so that\n",
            "when it came, she set up her small back and laughed\n",
            "with gurgling triumph. Sitting on the banks in this\n",
            "way, Silas began to look for the once familiar herbs\n",
            "again; and as the leaves, with their unchanged outline\n",
            "and markings, lay on his palm, there was a sense of\n",
            "crowding remembrances from which he turned away\n",
            "timidly, taking refuge in Eppie’s little world, that lay\n",
            "lightly on his enfeebled spirit.\n",
            "    As the child’s mind was growing into knowledge,\n",
            "his mind was growing into memory: as her life\n",
            "unfolded, his soul, long stupefied in a cold narrow\n",
            "prison, was unfolding too, and trembling gradually\n",
            "into full consciousness.\n",
            "    It was an influence which must gather force with\n",
            "every new year: the tones that stirred Silas’ heart\n",
            "grew articulate, and called for more distinct answers;\n",
            "shapes and sounds grew clearer for Eppie’s eyes and\n",
            "ears, and there was more that “Dad-dad” was\n",
            "imperatively required to notice and account for.\n",
            "Also, by the time Eppie was three years old, she\n",
            "developed a fine capacity for mischief, and for\n",
            "devising ingenious ways of being troublesome, which\n",
            "found much exercise, not only for Silas’ patience, but\n",
            "for his watchfulness and penetration. Sorely was poor\n",
            "Silas puzzled on such occasions by the incompatible\n",
            "demands of love.\n",
            "\n",
            "### Question:\n",
            "Which statement best describes a technique the narrator uses to represent Silas’s character before he adopted Eppie?\n",
            "\n",
            "### Choices:\n",
            "A) The narrator emphasizes Silas’s former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
            "B) The narrator underscores Silas’s former greed by describing his gold as seeming to reproduce on its own.\n",
            "C) The narrator hints at Silas’s former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
            "D) The narrator demonstrates Silas’s former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
            "\n",
            "Respond with ONLY the letter and full text of the correct answer.assistant\n",
            "\n",
            "A) The narrator emphasizes Silas’s former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n"
          ]
        }
      ],
      "source": [
        "tokenized_sample = generate_and_tokenize_prompt(sample_text, sample_answer)\n",
        "if tokenized_sample:\n",
        "    print(\"\\n=== Tokenized Sample ===\")\n",
        "    print(f\"Input IDs shape: {tokenized_sample['input_ids'].shape}\")\n",
        "    print(f\"Sample decoded back:\")\n",
        "    print(tokenizer.decode(tokenized_sample[\"input_ids\"], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_dataset(sample):\n",
        "    tokenized_sample = None\n",
        "    try:\n",
        "        processed_text = sample[\"text\"]\n",
        "        processed_answer = map_answer(sample[\"text\"], sample[\"answer\"].strip())\n",
        "        tokenized_sample = generate_and_tokenize_prompt(\n",
        "            processed_text, processed_answer\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping invalid sample: {e}\")\n",
        "    return tokenized_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = data.map(\n",
        "    preprocess_dataset,\n",
        "    remove_columns=data[\"train\"].column_names,\n",
        "    num_proc=4,\n",
        "    desc=\"Processing training dataset\",\n",
        ").filter(\n",
        "    lambda x: x is not None,\n",
        "    desc=\"Filtering out invalid samples\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 298\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 39\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 38\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "BaPiMgsl78ol",
        "outputId": "ef8d40c0-3575-4d2e-a594-e2fd74b0aee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min: 864, Max: 1396, Avg: 1128.0\n"
          ]
        }
      ],
      "source": [
        "# check length samples\n",
        "train_lengths = [len(x[\"input_ids\"]) for x in dataset[\"train\"]]  # type: ignore\n",
        "eval_lengths = [len(x[\"input_ids\"]) for x in dataset[\"validation\"]]  # type: ignore\n",
        "all_lengths = train_lengths + eval_lengths\n",
        "print(\n",
        "    f\"Min: {min(all_lengths)}, Max: {max(all_lengths)}, Avg: {sum(all_lengths)/len(all_lengths):.1f}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcpuJU9_bDJu"
      },
      "source": [
        "### 4.2. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ta_c_ISEP3xI"
      },
      "outputs": [],
      "source": [
        "from transformers.trainer_callback import TrainerCallback\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "\n",
        "\n",
        "class LogLossCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.console = Console()\n",
        "        self.table = Table(show_header=True, header_style=\"bold magenta\")\n",
        "        self.table.add_column(\"Step\", justify=\"right\")\n",
        "        self.table.add_column(\"Training Loss\", justify=\"right\")\n",
        "        self.logged_steps = set()\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is not None and \"loss\" in logs:\n",
        "            step = state.global_step\n",
        "            if step not in self.logged_steps:\n",
        "                loss = logs[\"loss\"]\n",
        "                self.table.add_row(str(step), f\"{loss:.6f}\")\n",
        "                self.logged_steps.add(step)\n",
        "\n",
        "                # if step % 10 == 0:\n",
        "                # self.console.clear()\n",
        "                self.console.print(self.table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaConfig {\n",
              "  \"_attn_implementation_autoset\": true,\n",
              "  \"architectures\": [\n",
              "    \"LlamaForCausalLM\"\n",
              "  ],\n",
              "  \"attention_bias\": false,\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 128000,\n",
              "  \"eos_token_id\": [\n",
              "    128001,\n",
              "    128008,\n",
              "    128009\n",
              "  ],\n",
              "  \"head_dim\": 64,\n",
              "  \"hidden_act\": \"silu\",\n",
              "  \"hidden_size\": 2048,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 8192,\n",
              "  \"max_position_embeddings\": 131072,\n",
              "  \"mlp_bias\": false,\n",
              "  \"model_type\": \"llama\",\n",
              "  \"num_attention_heads\": 32,\n",
              "  \"num_hidden_layers\": 16,\n",
              "  \"num_key_value_heads\": 8,\n",
              "  \"pretraining_tp\": 1,\n",
              "  \"quantization_config\": {\n",
              "    \"_load_in_4bit\": true,\n",
              "    \"_load_in_8bit\": false,\n",
              "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
              "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
              "    \"bnb_4bit_quant_type\": \"nf4\",\n",
              "    \"bnb_4bit_use_double_quant\": true,\n",
              "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
              "    \"llm_int8_has_fp16_weight\": false,\n",
              "    \"llm_int8_skip_modules\": null,\n",
              "    \"llm_int8_threshold\": 6.0,\n",
              "    \"load_in_4bit\": true,\n",
              "    \"load_in_8bit\": false,\n",
              "    \"quant_method\": \"bitsandbytes\"\n",
              "  },\n",
              "  \"rms_norm_eps\": 1e-05,\n",
              "  \"rope_scaling\": {\n",
              "    \"factor\": 32.0,\n",
              "    \"high_freq_factor\": 4.0,\n",
              "    \"low_freq_factor\": 1.0,\n",
              "    \"original_max_position_embeddings\": 8192,\n",
              "    \"rope_type\": \"llama3\"\n",
              "  },\n",
              "  \"rope_theta\": 500000.0,\n",
              "  \"tie_word_embeddings\": true,\n",
              "  \"torch_dtype\": \"float16\",\n",
              "  \"transformers_version\": \"4.52.0.dev0\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 128256\n",
              "}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(peft.peft_model.PeftModelForCausalLM,\n",
              " peft.peft_model.PeftModel,\n",
              " transformers.utils.hub.PushToHubMixin,\n",
              " torch.nn.modules.module.Module,\n",
              " object)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from peft import PeftModelForCausalLM\n",
        "\n",
        "PeftModelForCausalLM.__mro__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dW973laKADUH",
        "outputId": "9b25c740-cf38-4baa-8dbe-c6f0483570ba"
      },
      "outputs": [],
      "source": [
        "from transformers.training_args import TrainingArguments\n",
        "from transformers.trainer import Trainer\n",
        "from transformers.data.data_collator import DataCollatorForLanguageModeling\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    save_total_limit=3,\n",
        "    logging_steps=10,\n",
        "    output_dir=\"llama3-8b-sat-reading\",\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.05,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"loss\",\n",
        "    greater_is_better=False,\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=False, pad_to_multiple_of=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset = dataset.remove_columns([\"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "/home/tiviluson/miniconda3/envs/deeplearning/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='51' max='298' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 51/298 00:31 < 02:39, 1.55 it/s, Epoch 0.34/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/5 00:00 < 00:01, 2.57 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.904600 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.904600 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.904600 │\n",
              "│   20 │      2.637800 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.904600 │\n",
              "│   20 │      2.637800 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.904600 │\n",
              "│   20 │      2.637800 │\n",
              "│   30 │      2.334800 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.904600 │\n",
              "│   20 │      2.637800 │\n",
              "│   30 │      2.334800 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.904600 │\n",
              "│   20 │      2.637800 │\n",
              "│   30 │      2.334800 │\n",
              "│   40 │      2.335100 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.904600 │\n",
              "│   20 │      2.637800 │\n",
              "│   30 │      2.334800 │\n",
              "│   40 │      2.335100 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.904600 │\n",
              "│   20 │      2.637800 │\n",
              "│   30 │      2.334800 │\n",
              "│   40 │      2.335100 │\n",
              "│   50 │      2.202500 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.904600 │\n",
              "│   20 │      2.637800 │\n",
              "│   30 │      2.334800 │\n",
              "│   40 │      2.335100 │\n",
              "│   50 │      2.202500 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 4.68 GiB. GPU ",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# compiled_model = torch.compile(model)\u001b[39;00m\n\u001b[32m      7\u001b[39m trainer = Trainer(\n\u001b[32m      8\u001b[39m     model=model,\n\u001b[32m      9\u001b[39m     train_dataset=dataset[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     callbacks=[LogLossCallback()],\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/transformers/trainer.py:2239\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2237\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2238\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2240\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/transformers/trainer.py:2621\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2619\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.epoch = epoch + (step + \u001b[32m1\u001b[39m + steps_skipped) / steps_in_epoch\n\u001b[32m   2620\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2621\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2623\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2630\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2631\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2632\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_substep_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/transformers/trainer.py:3094\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3092\u001b[39m metrics = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3093\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_evaluate:\n\u001b[32m-> \u001b[39m\u001b[32m3094\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3095\u001b[39m     is_new_best_metric = \u001b[38;5;28mself\u001b[39m._determine_best_metric(metrics=metrics, trial=trial)\n\u001b[32m   3097\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_strategy == SaveStrategy.BEST:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/transformers/trainer.py:3043\u001b[39m, in \u001b[36mTrainer._evaluate\u001b[39m\u001b[34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[39m\n\u001b[32m   3042\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m3043\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3044\u001b[39m     \u001b[38;5;28mself\u001b[39m._report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m.state.global_step, metrics)\n\u001b[32m   3046\u001b[39m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/transformers/trainer.py:4172\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4169\u001b[39m start_time = time.time()\n\u001b[32m   4171\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m4172\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4173\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4175\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[32m   4176\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[32m   4177\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4180\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4182\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4183\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/transformers/trainer.py:4366\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4363\u001b[39m         batch_size = observed_batch_size\n\u001b[32m   4365\u001b[39m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4366\u001b[39m losses, logits, labels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4367\u001b[39m main_input_name = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmain_input_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4368\u001b[39m inputs_decode = (\n\u001b[32m   4369\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args.include_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4370\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/transformers/trainer.py:4582\u001b[39m, in \u001b[36mTrainer.prediction_step\u001b[39m\u001b[34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[39m\n\u001b[32m   4580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[32m   4581\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4582\u001b[39m         loss, outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   4583\u001b[39m     loss = loss.detach().mean()\n\u001b[32m   4585\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/transformers/trainer.py:3809\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3807\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3808\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3809\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3810\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3811\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/accelerate/utils/operations.py:814\u001b[39m, in \u001b[36mconvert_outputs_to_fp32.<locals>.forward\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    813\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m814\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/accelerate/utils/operations.py:802\u001b[39m, in \u001b[36mConvertOutputsToFp32.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/torch/amp/autocast_mode.py:16\u001b[39m, in \u001b[36mautocast_decorator.<locals>.decorate_autocast\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_autocast\u001b[39m(*args, **kwargs):\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/peft/peft_model.py:1732\u001b[39m, in \u001b[36mPeftModelForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[39m\n\u001b[32m   1730\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(**kwargs):\n\u001b[32m   1731\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1732\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1733\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1734\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1735\u001b[39m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1736\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1737\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1738\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1739\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1740\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1741\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1743\u001b[39m batch_size = _get_batch_size(input_ids, inputs_embeds)\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:194\u001b[39m, in \u001b[36mBaseTuner.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any):\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/transformers/utils/generic.py:969\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    971\u001b[39m         output = output.to_tuple()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:829\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m loss = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CausalLMOutputWithPast(\n\u001b[32m    832\u001b[39m     loss=loss,\n\u001b[32m    833\u001b[39m     logits=logits,\n\u001b[32m   (...)\u001b[39m\u001b[32m    836\u001b[39m     attentions=outputs.attentions,\n\u001b[32m    837\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/transformers/loss/loss_utils.py:64\u001b[39m, in \u001b[36mForCausalLMLoss\u001b[39m\u001b[34m(logits, labels, vocab_size, num_items_in_batch, ignore_index, shift_labels, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Enable model parallelism\u001b[39;00m\n\u001b[32m     63\u001b[39m shift_labels = shift_labels.to(logits.device)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m loss = \u001b[43mfixed_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/transformers/loss/loss_utils.py:36\u001b[39m, in \u001b[36mfixed_cross_entropy\u001b[39m\u001b[34m(source, target, num_items_in_batch, ignore_index, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfixed_cross_entropy\u001b[39m(\n\u001b[32m     29\u001b[39m     source: torch.Tensor,\n\u001b[32m     30\u001b[39m     target: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     **kwargs,\n\u001b[32m     34\u001b[39m ) -> torch.Tensor:\n\u001b[32m     35\u001b[39m     reduction = \u001b[33m\"\u001b[39m\u001b[33msum\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     loss = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m reduction == \u001b[33m\"\u001b[39m\u001b[33msum\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     38\u001b[39m         loss = loss / num_items_in_batch\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deeplearning/lib/python3.11/site-packages/torch/nn/functional.py:3086\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3084\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3085\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3086\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 4.68 GiB. GPU "
          ]
        }
      ],
      "source": [
        "# Quantization-aware training settings\n",
        "model.config.use_cache = False\n",
        "model.enable_input_require_grads()\n",
        "# compiled_model = torch.compile(model)\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    callbacks=[LogLossCallback()],\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deeplearning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02d8fb58beaa4ca4a2598ef3543762df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5798421a0533435aaa7f2de0bb5e7d14",
            "placeholder": "​",
            "style": "IPY_MODEL_080472662db946a5bd667b3520e0cb26",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "0337ef0f697847428055499bb1816882": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c404b05899104b5380a6efaf069f638d",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d843e4f5a7934b09bddf1ae6427d433a",
            "value": 3
          }
        },
        "080472662db946a5bd667b3520e0cb26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09af949d22f0452c975cd62c89f76081": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e93e52e4cb614b0797b205200fa2a49b",
            "placeholder": "​",
            "style": "IPY_MODEL_9404b36393064f7590998f9d581b559a",
            "value": " 726/726 [00:00&lt;00:00, 28.4kB/s]"
          }
        },
        "09e4bfab03f0418491ac9d98b533ede8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c917ed275f2464d90ce210fc5ae5589": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8843aaad1654a5c87aec8788dd3178b",
            "placeholder": "​",
            "style": "IPY_MODEL_5778a2b89be94a39aac59fd3db7f77ce",
            "value": " 3/3 [00:45&lt;00:00, 12.57s/it]"
          }
        },
        "13bc9121cedc471ab1b9b78af6923dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14c8472c50f9451781a9f50b52581791": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a2d9a2b8a5d43e9894c679ff280e4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ec3af33c0294ad6acf59ef462cdf01f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22c76b133fe844ed838445ed7cb1f827": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23eede34912c440e80f4f7499584eb21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3060dbfc567f419da3659aef56ea01d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2272ea1c70b4f679db18564fcd9cf0b",
              "IPY_MODEL_c3537858fbf2432fb4233660ae3cf473",
              "IPY_MODEL_435c8186f1f14ad1ad773580c1fddb5e"
            ],
            "layout": "IPY_MODEL_e35cbba17f144dfb940217a5415a0031"
          }
        },
        "325ba8666f504335a36ef9a91838e88c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35018d3b29e44833900ce8a12b846ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "384a9fc5f4864f35b5a3ff4e79cb1a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23eede34912c440e80f4f7499584eb21",
            "placeholder": "​",
            "style": "IPY_MODEL_e8e9a5df7a124dae833c36dbc48903d2",
            "value": "config.json: 100%"
          }
        },
        "38f9d09e9dec42eab7e89265783f707e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39cd48f27b624a3bbf462d7084694daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa877365d56b48fc91f30f523f30a6ca",
            "placeholder": "​",
            "style": "IPY_MODEL_14c8472c50f9451781a9f50b52581791",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3f60b06695f84d75821aff3ba8563328": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f6f2e2bc8aa408bb70370f2bbae1305": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ff234a90d8c465a822567c3bc5d0b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "435c8186f1f14ad1ad773580c1fddb5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b525a1fa82bd4e589450c6994266d293",
            "placeholder": "​",
            "style": "IPY_MODEL_c51649878ab14382a3c44f3b3398f3e3",
            "value": " 3.99G/3.99G [00:50&lt;00:00, 124MB/s]"
          }
        },
        "43cd862c77d34fed8b69ab2538a17804": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4694dff5920642ecbb4d4f5038af964b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d981321871940a9993deaa43f2086ed",
            "max": 45118424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60358b23734848f3a5f53b54df9d1d72",
            "value": 45118424
          }
        },
        "4d04d65e0bfe48998adb544d1b084ddc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d981321871940a9993deaa43f2086ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5587cf5cef334d7d8e0f65b25efc66f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57553c3f2dd949b1b7e280d192d7012b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5778a2b89be94a39aac59fd3db7f77ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5798421a0533435aaa7f2de0bb5e7d14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5af8494cb1724593864ee0aa4633a674": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d44e2d2de8f40b1bd15348805d6638a",
            "max": 99630640,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57553c3f2dd949b1b7e280d192d7012b",
            "value": 99630640
          }
        },
        "5d3bacd68db346e8858f24ee2a184128": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d44e2d2de8f40b1bd15348805d6638a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60358b23734848f3a5f53b54df9d1d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60a0432c24a243e391a38ff61b714120": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "683e243ec4f749e3a3060db7e28c27e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebd96abb117e421593563f10fc2612a3",
            "placeholder": "​",
            "style": "IPY_MODEL_13bc9121cedc471ab1b9b78af6923dce",
            "value": " 239/239 [00:00&lt;00:00, 25.9kB/s]"
          }
        },
        "6abe1b81c4de491da5ea2c6f634efb23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_384a9fc5f4864f35b5a3ff4e79cb1a63",
              "IPY_MODEL_c1c5f226c7b74f59bc2a3921cae04942",
              "IPY_MODEL_09af949d22f0452c975cd62c89f76081"
            ],
            "layout": "IPY_MODEL_35018d3b29e44833900ce8a12b846ac6"
          }
        },
        "6c33c895e5ca4ab1a01f8b8d697a7f0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7155a0f7974b4d7f8320b31a550f1d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed1e08bad6bc41029d7d2df69bf04398",
            "placeholder": "​",
            "style": "IPY_MODEL_5d3bacd68db346e8858f24ee2a184128",
            "value": " 32.8k/32.8k [00:00&lt;00:00, 853kB/s]"
          }
        },
        "75cb94e6c96e43839736ec0891de189a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b25d945250e4c36a355a87783d71446": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "876f8027f61a4b4faf2b767f96bddc07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87d6b994470e4d3c96308e9e64125bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39cd48f27b624a3bbf462d7084694daf",
              "IPY_MODEL_0337ef0f697847428055499bb1816882",
              "IPY_MODEL_0c917ed275f2464d90ce210fc5ae5589"
            ],
            "layout": "IPY_MODEL_dfd583d5e301470fa9598d59bdc216a8"
          }
        },
        "8a5cb53d6fbe4548b944f7484320456d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc61f74ed1b14b3694b25cb82582665f",
            "placeholder": "​",
            "style": "IPY_MODEL_b2f2a73b79964f47b1224e014e5eac7d",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "90777168817640b48a3084ea2bc423ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "927d64bddb904f19957e54a93d0c19c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5587cf5cef334d7d8e0f65b25efc66f0",
            "max": 32819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed99799943f341cf942f29c3a3b6548e",
            "value": 32819
          }
        },
        "9404b36393064f7590998f9d581b559a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9633119f97734bbfa5b7ce35231c09aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d04d65e0bfe48998adb544d1b084ddc",
            "placeholder": "​",
            "style": "IPY_MODEL_3f60b06695f84d75821aff3ba8563328",
            "value": " 45.1M/45.1M [00:06&lt;00:00, 6.17MB/s]"
          }
        },
        "9744605e38244b16b2a37714908ca02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9855862689694f869e4112aec21522e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b25d945250e4c36a355a87783d71446",
            "placeholder": "​",
            "style": "IPY_MODEL_3ff234a90d8c465a822567c3bc5d0b91",
            "value": "Fetching 3 files: 100%"
          }
        },
        "98c2bd9ac28c4134922a9960673d2787": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c55c7897e14151a3572213f50d73e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f65353e8b8b4120bd2bcb5b3b06d031": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a03ebb1614814a46a6420c76715b1b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9855862689694f869e4112aec21522e9",
              "IPY_MODEL_e7400616a60441d484b4981ec2cf10e8",
              "IPY_MODEL_b125bdae8a30455dbfbf55c015fe3b8a"
            ],
            "layout": "IPY_MODEL_9f65353e8b8b4120bd2bcb5b3b06d031"
          }
        },
        "a9383793c8314e7ead63f84dc6fe1f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa877365d56b48fc91f30f523f30a6ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abcd79cf38224fb48f4d26c6c3a298c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98c2bd9ac28c4134922a9960673d2787",
            "placeholder": "​",
            "style": "IPY_MODEL_09e4bfab03f0418491ac9d98b533ede8",
            "value": " 99.6M/99.6M [00:03&lt;00:00, 16.2MB/s]"
          }
        },
        "ad01da3f35b64321be81883f2c97286f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "add3c056f42a483d82d0a65fe0e18b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeb1c60cd19b4f06a883f220ab96d91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1e0dbc30e2647b0a292b58fc6a71df3",
              "IPY_MODEL_927d64bddb904f19957e54a93d0c19c4",
              "IPY_MODEL_7155a0f7974b4d7f8320b31a550f1d44"
            ],
            "layout": "IPY_MODEL_98c55c7897e14151a3572213f50d73e2"
          }
        },
        "afcba9881fd5466f85620d8ee5dedfeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0cc63548c3d412a971d47aae59440ef",
            "max": 3957900840,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60a0432c24a243e391a38ff61b714120",
            "value": 3957900840
          }
        },
        "b125bdae8a30455dbfbf55c015fe3b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75cb94e6c96e43839736ec0891de189a",
            "placeholder": "​",
            "style": "IPY_MODEL_3f6f2e2bc8aa408bb70370f2bbae1305",
            "value": " 3/3 [00:50&lt;00:00, 50.33s/it]"
          }
        },
        "b2f2a73b79964f47b1224e014e5eac7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b525a1fa82bd4e589450c6994266d293": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72df54a1c424715a802d01ebf224053": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbd8301c0b9e47dba8680a73b52c849b",
              "IPY_MODEL_d07383055fd64c57b6caa209d2ad74ca",
              "IPY_MODEL_683e243ec4f749e3a3060db7e28c27e4"
            ],
            "layout": "IPY_MODEL_38f9d09e9dec42eab7e89265783f707e"
          }
        },
        "bcbc7cc0d577454d8629c1960ba6cdfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9fc835ef2094721aaec3a844c88c998",
              "IPY_MODEL_afcba9881fd5466f85620d8ee5dedfeb",
              "IPY_MODEL_fb5a55058d564fb18ada5509a1b3ca2d"
            ],
            "layout": "IPY_MODEL_ad01da3f35b64321be81883f2c97286f"
          }
        },
        "c115b67bf75e43069c5c6831b0ae7148": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1c5f226c7b74f59bc2a3921cae04942": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e032c9c1bc446ba2593a293a1b677c",
            "max": 726,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43cd862c77d34fed8b69ab2538a17804",
            "value": 726
          }
        },
        "c3537858fbf2432fb4233660ae3cf473": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db27042cb6574d0a9cb4a8a2613da7b0",
            "max": 3987450520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e17a2332f3284668990cfdf3f9c8ec75",
            "value": 3987450520
          }
        },
        "c404b05899104b5380a6efaf069f638d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4aa5a97889444b09bfb6ba358e557b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a5cb53d6fbe4548b944f7484320456d",
              "IPY_MODEL_4694dff5920642ecbb4d4f5038af964b",
              "IPY_MODEL_9633119f97734bbfa5b7ce35231c09aa"
            ],
            "layout": "IPY_MODEL_1ec3af33c0294ad6acf59ef462cdf01f"
          }
        },
        "c51649878ab14382a3c44f3b3398f3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c83973f019534568834367797ae9b9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8e032c9c1bc446ba2593a293a1b677c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9fc835ef2094721aaec3a844c88c998": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22c76b133fe844ed838445ed7cb1f827",
            "placeholder": "​",
            "style": "IPY_MODEL_90777168817640b48a3084ea2bc423ca",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "cbd8301c0b9e47dba8680a73b52c849b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4e69a606a684948940e9cc44b24b00d",
            "placeholder": "​",
            "style": "IPY_MODEL_c115b67bf75e43069c5c6831b0ae7148",
            "value": "generation_config.json: 100%"
          }
        },
        "d07383055fd64c57b6caa209d2ad74ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_876f8027f61a4b4faf2b767f96bddc07",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a2d9a2b8a5d43e9894c679ff280e4b5",
            "value": 239
          }
        },
        "d843e4f5a7934b09bddf1ae6427d433a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db27042cb6574d0a9cb4a8a2613da7b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfd583d5e301470fa9598d59bdc216a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e115c0667a2c445ab65b16a4f38bd8f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e17a2332f3284668990cfdf3f9c8ec75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1e0dbc30e2647b0a292b58fc6a71df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc203ffc1e46468cb527b067b4e74ecd",
            "placeholder": "​",
            "style": "IPY_MODEL_add3c056f42a483d82d0a65fe0e18b2a",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "e35cbba17f144dfb940217a5415a0031": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e61b6aec69654ee9bf845ec79c6259ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7400616a60441d484b4981ec2cf10e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c33c895e5ca4ab1a01f8b8d697a7f0b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c83973f019534568834367797ae9b9ec",
            "value": 3
          }
        },
        "e8e9a5df7a124dae833c36dbc48903d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e93e52e4cb614b0797b205200fa2a49b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebd96abb117e421593563f10fc2612a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed1e08bad6bc41029d7d2df69bf04398": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed99799943f341cf942f29c3a3b6548e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef8c4198e92f41c294297349b9a82b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02d8fb58beaa4ca4a2598ef3543762df",
              "IPY_MODEL_5af8494cb1724593864ee0aa4633a674",
              "IPY_MODEL_abcd79cf38224fb48f4d26c6c3a298c9"
            ],
            "layout": "IPY_MODEL_a9383793c8314e7ead63f84dc6fe1f9f"
          }
        },
        "f0cc63548c3d412a971d47aae59440ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2272ea1c70b4f679db18564fcd9cf0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e61b6aec69654ee9bf845ec79c6259ab",
            "placeholder": "​",
            "style": "IPY_MODEL_9744605e38244b16b2a37714908ca02f",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "f4e69a606a684948940e9cc44b24b00d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8843aaad1654a5c87aec8788dd3178b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb5a55058d564fb18ada5509a1b3ca2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_325ba8666f504335a36ef9a91838e88c",
            "placeholder": "​",
            "style": "IPY_MODEL_e115c0667a2c445ab65b16a4f38bd8f4",
            "value": " 3.96G/3.96G [00:50&lt;00:00, 109MB/s]"
          }
        },
        "fc203ffc1e46468cb527b067b4e74ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc61f74ed1b14b3694b25cb82582665f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
