{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finetuning LLM for SAT Reading section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97NYN3e_6BcS"
      },
      "source": [
        "## 1. Install and import necessary libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO59tP-Bvion",
        "outputId": "e156fce3-6ae9-41ab-c471-0e19d315ea95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U datasets\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U loralib\n",
        "!pip install -q -U einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1g4cs-qYwjtO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1sJVa39vRct"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['HF_TOKEN'] =  userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL3aZuZr6LRp"
      },
      "source": [
        "## 2. Load pre-trained LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kFK18GDxMaW"
      },
      "outputs": [],
      "source": [
        "from transformers.utils.quantization_config import BitsAndBytesConfig\n",
        "\n",
        "MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "# MODEL_NAME = \"Qwen/Qwen3-4B\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "09c07700e8b844ac8e7f3fa39b7fcb55",
            "b83a2cd256c04c699539018f70cb5a7a",
            "f442d04ac9f141d79442ff666b3ec9f8",
            "1338635003604ef9a381ae4e90656d13",
            "6460f5fa30204966940ab5fefa88089b",
            "103394bacaa74355becf76ec07659918",
            "e0b95d0377ab412d8f4969e98fa984ac",
            "66b48f0fea604a7993254d6f9c6e2f76",
            "f5ac4102937f4760a229245b0f358569",
            "225c8653a2414033a39c5e55f4d287a6",
            "7ccd7e29f94247e0ad27ae4d978820c7"
          ]
        },
        "id": "cW56RiCyHp09",
        "outputId": "096afbf7-b0c3-4347-bc3f-e9ff69a5a062"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09c07700e8b844ac8e7f3fa39b7fcb55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading tokenizer...\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"cuda:0\",\n",
        "    offload_state_dict=True,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "print(\"Loading tokenizer...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZs0QUBIHp09",
        "outputId": "0156f065-a06f-483f-c77d-a8166bc5cdb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 3072)\n",
              "    (layers): ModuleList(\n",
              "      (0-27): 28 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJEtVaVXHp09"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dldnmiv5uf7h",
        "outputId": "0bc4ac4d-ae28-404e-b89a-03c4a5bc4d94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.special_tokens_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFPYBrfzuf7h"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3IyFZsPP3xC"
      },
      "outputs": [],
      "source": [
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTdJED99uf7h",
        "outputId": "6406c911-6a62-47a0-d531-e1f43acae5ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 3072)\n",
              "    (layers): ModuleList(\n",
              "      (0-27): 28 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leNliYBZ0IqT"
      },
      "outputs": [],
      "source": [
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzKxEualuf7i",
        "outputId": "83f95372-9feb-4c46-efc7-41286b304f13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 24,313,856 || all params: 3,237,063,680 || trainable%: 0.7511\n"
          ]
        }
      ],
      "source": [
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LtPfrh4uf7i",
        "outputId": "2c369892-308a-40ea-8092-5fe0651813a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Free memory: 16.98 GB\n",
            "Total memory: 22.16 GB\n"
          ]
        }
      ],
      "source": [
        "mem_free, mem_total = torch.cuda.mem_get_info()\n",
        "print(f\"Free memory: {mem_free / 1024**3:.2f} GB\")\n",
        "print(f\"Total memory: {mem_total / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZFDIeG4uf7i",
        "outputId": "11812cc1-9a1c-4711-858b-81d08f7c1e73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 3072)\n",
              "        (layers): ModuleList(\n",
              "          (0-27): 28 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY2I1hXZa4Qt"
      },
      "source": [
        "## 3. Test pre-trained model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhX68KkaP3xD"
      },
      "outputs": [],
      "source": [
        "from transformers.generation.configuration_utils import GenerationConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B56-xXB6P3xE"
      },
      "outputs": [],
      "source": [
        "# Llama-3's official system prompt structure\n",
        "LLAMA3_SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant developed by Meta. Respond safely and accurately.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5aDJcvm0PDj"
      },
      "outputs": [],
      "source": [
        "# Test pretrained model performance\n",
        "prompt = [\n",
        "    {\"role\": \"system\", \"content\": LLAMA3_SYSTEM_PROMPT},\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Analyze the given passage and question. Choose the best answer from the options below.\n",
        "\n",
        "### Passage:\n",
        "[This passage is adapted from George Eliot, Silas Marner. Originally published in 1861. Silas was a weaver and a notorious miser, but then the gold he had hoarded was stolen. Shortly after, Silas adopted a young child, Eppie, the daughter of an impoverished woman who had died suddenly.\n",
        "\n",
        "    Unlike the gold which needed nothing, and must\n",
        "be worshipped in close-locked solitude—which was\n",
        "hidden away from the daylight, was deaf to the song\n",
        "of birds, and started to no human tones—Eppie was a\n",
        "creature of endless claims and ever-growing desires,\n",
        "seeking and loving sunshine, and living sounds, and\n",
        "living movements; making trial of everything, with\n",
        "trust in new joy, and stirring the human kindness in\n",
        "all eyes that looked on her. The gold had kept his\n",
        "thoughts in an ever-repeated circle, leading to\n",
        "nothing beyond itself; but Eppie was an object\n",
        "compacted of changes and hopes that forced his\n",
        "thoughts onward, and carried them far away from\n",
        "their old eager pacing towards the same blank\n",
        "limit—carried them away to the new things that\n",
        "would come with the coming years, when Eppie\n",
        "would have learned to understand how her father\n",
        "Silas cared for her; and made him look for images of\n",
        "that time in the ties and charities that bound together\n",
        "the families of his neighbors. The gold had asked that\n",
        "he should sit weaving longer and longer, deafened\n",
        "and blinded more and more to all things except the\n",
        "monotony of his loom and the repetition of his web;\n",
        "but Eppie called him away from his weaving, and\n",
        "made him think all its pauses a holiday, reawakening\n",
        "his senses with her fresh life, even to the old\n",
        "winter-flies that came crawling forth in the early\n",
        "spring sunshine, and warming him into joy because\n",
        "she had joy.\n",
        "    And when the sunshine grew strong and lasting,\n",
        "so that the buttercups were thick in the meadows,\n",
        "Silas might be seen in the sunny mid-day, or in the\n",
        "late afternoon when the shadows were lengthening\n",
        "under the hedgerows, strolling out with uncovered\n",
        "head to carry Eppie beyond the Stone-pits to where\n",
        "the flowers grew, till they reached some favorite bank\n",
        "where he could sit down, while Eppie toddled to\n",
        "pluck the flowers, and make remarks to the winged\n",
        "things that murmured happily above the bright\n",
        "petals, calling “Dad-dad’s” attention continually by\n",
        "bringing him the flowers. Then she would turn her\n",
        "ear to some sudden bird-note, and Silas learned to\n",
        "please her by making signs of hushed stillness, that\n",
        "they might listen for the note to come again: so that\n",
        "when it came, she set up her small back and laughed\n",
        "with gurgling triumph. Sitting on the banks in this\n",
        "way, Silas began to look for the once familiar herbs\n",
        "again; and as the leaves, with their unchanged outline\n",
        "and markings, lay on his palm, there was a sense of\n",
        "crowding remembrances from which he turned away\n",
        "timidly, taking refuge in Eppie’s little world, that lay\n",
        "lightly on his enfeebled spirit.\n",
        "    As the child’s mind was growing into knowledge,\n",
        "his mind was growing into memory: as her life\n",
        "unfolded, his soul, long stupefied in a cold narrow\n",
        "prison, was unfolding too, and trembling gradually\n",
        "into full consciousness.\n",
        "    It was an influence which must gather force with\n",
        "every new year: the tones that stirred Silas’ heart\n",
        "grew articulate, and called for more distinct answers;\n",
        "shapes and sounds grew clearer for Eppie’s eyes and\n",
        "ears, and there was more that “Dad-dad” was\n",
        "imperatively required to notice and account for.\n",
        "Also, by the time Eppie was three years old, she\n",
        "developed a fine capacity for mischief, and for\n",
        "devising ingenious ways of being troublesome, which\n",
        "found much exercise, not only for Silas’ patience, but\n",
        "for his watchfulness and penetration. Sorely was poor\n",
        "Silas puzzled on such occasions by the incompatible\n",
        "demands of love.]\n",
        "\n",
        "### Question:\n",
        "Which statement best describes a technique the narrator uses to represent Silas's character before he adopted Eppie?\n",
        "\n",
        "### Choices:\n",
        "A) The narrator emphasizes Silas's former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
        "B) The narrator underscores Silas's former greed by describing his gold as seeming to reproduce on its own.\n",
        "C) The narrator hints at Silas's former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
        "D) The narrator demonstrates Silas's former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
        "\n",
        "Respond ONLY with the letter and full text of the correct answer choice.\"\"\",\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omOhqLdnuf7i",
        "outputId": "565ce083-4a79-4554-cfee-6fb90bea16a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 05 May 2025\n",
            "\n",
            "You are a helpful AI assistant developed by Meta. Respond safely and accurately.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Analyze the given passage and question. Choose the best answer from the options below.\n",
            "\n",
            "### Passage:\n",
            "[This passage is adapted from George Eliot, Silas Marner. Originally published in 1861. Silas was a weaver and a notorious miser, but then the gold he had hoarded was stolen. Shortly after, Silas adopted a young child, Eppie, the daughter of an impoverished woman who had died suddenly.\n",
            "\n",
            "    Unlike the gold which needed nothing, and must\n",
            "be worshipped in close-locked solitude—which was\n",
            "hidden away from the daylight, was deaf to the song\n",
            "of birds, and started to no human tones—Eppie was a\n",
            "creature of endless claims and ever-growing desires,\n",
            "seeking and loving sunshine, and living sounds, and\n",
            "living movements; making trial of everything, with\n",
            "trust in new joy, and stirring the human kindness in\n",
            "all eyes that looked on her. The gold had kept his\n",
            "thoughts in an ever-repeated circle, leading to\n",
            "nothing beyond itself; but Eppie was an object\n",
            "compacted of changes and hopes that forced his\n",
            "thoughts onward, and carried them far away from\n",
            "their old eager pacing towards the same blank\n",
            "limit—carried them away to the new things that\n",
            "would come with the coming years, when Eppie\n",
            "would have learned to understand how her father\n",
            "Silas cared for her; and made him look for images of\n",
            "that time in the ties and charities that bound together\n",
            "the families of his neighbors. The gold had asked that\n",
            "he should sit weaving longer and longer, deafened\n",
            "and blinded more and more to all things except the\n",
            "monotony of his loom and the repetition of his web;\n",
            "but Eppie called him away from his weaving, and\n",
            "made him think all its pauses a holiday, reawakening\n",
            "his senses with her fresh life, even to the old\n",
            "winter-flies that came crawling forth in the early\n",
            "spring sunshine, and warming him into joy because\n",
            "she had joy.\n",
            "    And when the sunshine grew strong and lasting,\n",
            "so that the buttercups were thick in the meadows,\n",
            "Silas might be seen in the sunny mid-day, or in the\n",
            "late afternoon when the shadows were lengthening\n",
            "under the hedgerows, strolling out with uncovered\n",
            "head to carry Eppie beyond the Stone-pits to where\n",
            "the flowers grew, till they reached some favorite bank\n",
            "where he could sit down, while Eppie toddled to\n",
            "pluck the flowers, and make remarks to the winged\n",
            "things that murmured happily above the bright\n",
            "petals, calling “Dad-dad’s” attention continually by\n",
            "bringing him the flowers. Then she would turn her\n",
            "ear to some sudden bird-note, and Silas learned to\n",
            "please her by making signs of hushed stillness, that\n",
            "they might listen for the note to come again: so that\n",
            "when it came, she set up her small back and laughed\n",
            "with gurgling triumph. Sitting on the banks in this\n",
            "way, Silas began to look for the once familiar herbs\n",
            "again; and as the leaves, with their unchanged outline\n",
            "and markings, lay on his palm, there was a sense of\n",
            "crowding remembrances from which he turned away\n",
            "timidly, taking refuge in Eppie’s little world, that lay\n",
            "lightly on his enfeebled spirit.\n",
            "    As the child’s mind was growing into knowledge,\n",
            "his mind was growing into memory: as her life\n",
            "unfolded, his soul, long stupefied in a cold narrow\n",
            "prison, was unfolding too, and trembling gradually\n",
            "into full consciousness.\n",
            "    It was an influence which must gather force with\n",
            "every new year: the tones that stirred Silas’ heart\n",
            "grew articulate, and called for more distinct answers;\n",
            "shapes and sounds grew clearer for Eppie’s eyes and\n",
            "ears, and there was more that “Dad-dad” was\n",
            "imperatively required to notice and account for.\n",
            "Also, by the time Eppie was three years old, she\n",
            "developed a fine capacity for mischief, and for\n",
            "devising ingenious ways of being troublesome, which\n",
            "found much exercise, not only for Silas’ patience, but\n",
            "for his watchfulness and penetration. Sorely was poor\n",
            "Silas puzzled on such occasions by the incompatible\n",
            "demands of love.]\n",
            "\n",
            "### Question:\n",
            "Which statement best describes a technique the narrator uses to represent Silas's character before he adopted Eppie?\n",
            "\n",
            "### Choices:\n",
            "A) The narrator emphasizes Silas's former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
            "B) The narrator underscores Silas's former greed by describing his gold as seeming to reproduce on its own.\n",
            "C) The narrator hints at Silas's former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
            "D) The narrator demonstrates Silas's former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
            "\n",
            "Respond ONLY with the letter and full text of the correct answer choice.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Apply chat template (text only)\n",
        "chat_text = tokenizer.apply_chat_template(\n",
        "    prompt, add_generation_prompt=True, tokenize=False\n",
        ")\n",
        "print(chat_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnrbBGUJuf7i",
        "outputId": "041ade16-0a3d-46b2-c0d3-74060b0776e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [128000, 128000, 128001], 'attention_mask': [1, 1, 1]}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\"<|begin_of_text|><|end_of_text|>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm2A87Nfuf7i",
        "outputId": "3b4a25f2-f1d8-4193-8798-2421d8d8bdf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids: torch.Size([1, 1104])\n",
            "attention_mask: torch.Size([1, 1104])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Tokenize\n",
        "inputs = tokenizer(chat_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "for k, v in inputs.items():\n",
        "    print(f\"{k}: {v.shape}\")\n",
        "v.all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8P1Qqcj0VIe",
        "outputId": "6e00c22a-424c-48be-a346-8e6cfd5e9c12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 05 May 2025\n",
            "\n",
            "You are a helpful AI assistant developed by Meta. Respond safely and accurately.user\n",
            "\n",
            "Analyze the given passage and question. Choose the best answer from the options below.\n",
            "\n",
            "### Passage:\n",
            "[This passage is adapted from George Eliot, Silas Marner. Originally published in 1861. Silas was a weaver and a notorious miser, but then the gold he had hoarded was stolen. Shortly after, Silas adopted a young child, Eppie, the daughter of an impoverished woman who had died suddenly.\n",
            "\n",
            "    Unlike the gold which needed nothing, and must\n",
            "be worshipped in close-locked solitude—which was\n",
            "hidden away from the daylight, was deaf to the song\n",
            "of birds, and started to no human tones—Eppie was a\n",
            "creature of endless claims and ever-growing desires,\n",
            "seeking and loving sunshine, and living sounds, and\n",
            "living movements; making trial of everything, with\n",
            "trust in new joy, and stirring the human kindness in\n",
            "all eyes that looked on her. The gold had kept his\n",
            "thoughts in an ever-repeated circle, leading to\n",
            "nothing beyond itself; but Eppie was an object\n",
            "compacted of changes and hopes that forced his\n",
            "thoughts onward, and carried them far away from\n",
            "their old eager pacing towards the same blank\n",
            "limit—carried them away to the new things that\n",
            "would come with the coming years, when Eppie\n",
            "would have learned to understand how her father\n",
            "Silas cared for her; and made him look for images of\n",
            "that time in the ties and charities that bound together\n",
            "the families of his neighbors. The gold had asked that\n",
            "he should sit weaving longer and longer, deafened\n",
            "and blinded more and more to all things except the\n",
            "monotony of his loom and the repetition of his web;\n",
            "but Eppie called him away from his weaving, and\n",
            "made him think all its pauses a holiday, reawakening\n",
            "his senses with her fresh life, even to the old\n",
            "winter-flies that came crawling forth in the early\n",
            "spring sunshine, and warming him into joy because\n",
            "she had joy.\n",
            "    And when the sunshine grew strong and lasting,\n",
            "so that the buttercups were thick in the meadows,\n",
            "Silas might be seen in the sunny mid-day, or in the\n",
            "late afternoon when the shadows were lengthening\n",
            "under the hedgerows, strolling out with uncovered\n",
            "head to carry Eppie beyond the Stone-pits to where\n",
            "the flowers grew, till they reached some favorite bank\n",
            "where he could sit down, while Eppie toddled to\n",
            "pluck the flowers, and make remarks to the winged\n",
            "things that murmured happily above the bright\n",
            "petals, calling “Dad-dad’s” attention continually by\n",
            "bringing him the flowers. Then she would turn her\n",
            "ear to some sudden bird-note, and Silas learned to\n",
            "please her by making signs of hushed stillness, that\n",
            "they might listen for the note to come again: so that\n",
            "when it came, she set up her small back and laughed\n",
            "with gurgling triumph. Sitting on the banks in this\n",
            "way, Silas began to look for the once familiar herbs\n",
            "again; and as the leaves, with their unchanged outline\n",
            "and markings, lay on his palm, there was a sense of\n",
            "crowding remembrances from which he turned away\n",
            "timidly, taking refuge in Eppie’s little world, that lay\n",
            "lightly on his enfeebled spirit.\n",
            "    As the child’s mind was growing into knowledge,\n",
            "his mind was growing into memory: as her life\n",
            "unfolded, his soul, long stupefied in a cold narrow\n",
            "prison, was unfolding too, and trembling gradually\n",
            "into full consciousness.\n",
            "    It was an influence which must gather force with\n",
            "every new year: the tones that stirred Silas’ heart\n",
            "grew articulate, and called for more distinct answers;\n",
            "shapes and sounds grew clearer for Eppie’s eyes and\n",
            "ears, and there was more that “Dad-dad” was\n",
            "imperatively required to notice and account for.\n",
            "Also, by the time Eppie was three years old, she\n",
            "developed a fine capacity for mischief, and for\n",
            "devising ingenious ways of being troublesome, which\n",
            "found much exercise, not only for Silas’ patience, but\n",
            "for his watchfulness and penetration. Sorely was poor\n",
            "Silas puzzled on such occasions by the incompatible\n",
            "demands of love.]\n",
            "\n",
            "### Question:\n",
            "Which statement best describes a technique the narrator uses to represent Silas's character before he adopted Eppie?\n",
            "\n",
            "### Choices:\n",
            "A) The narrator emphasizes Silas's former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
            "B) The narrator underscores Silas's former greed by describing his gold as seeming to reproduce on its own.\n",
            "C) The narrator hints at Silas's former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
            "D) The narrator demonstrates Silas's former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
            "\n",
            "Respond ONLY with the letter and full text of the correct answer choice.assistant\n",
            "\n",
            "A)\n",
            "Unlike the gold which needed nothing, and must \n",
            "be worshipped in close-locked solitude—which was \n",
            "hidden away from the daylight, was deaf to the song \n",
            "of birds, and started to no human tones—Eppie was a\n"
          ]
        }
      ],
      "source": [
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.01,\n",
        "    do_sample=True,\n",
        "    num_return_sequences=1,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    repetition_penalty=1.3,\n",
        ")\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        generation_config=generation_config,\n",
        "    )\n",
        "\n",
        "    # Decode output\n",
        "output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "# print\n",
        "if \"<|assistant|>\" in output_text:\n",
        "    print(output_text.split(\"<|assistant|>\")[-1].strip())\n",
        "else:\n",
        "    print(output_text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK7lUW10a9d5"
      },
      "source": [
        "## 4. Fine-tuning LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKzaGrv2a_fg"
      },
      "source": [
        "### 4.1. Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DfuFAseuf7i"
      },
      "outputs": [],
      "source": [
        "from datasets.dataset_dict import DatasetDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwPC_aBB6VXm"
      },
      "outputs": [],
      "source": [
        "data: DatasetDict = load_dataset(\"emozilla/sat-reading\")  # type: ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImH26GW96vbB",
        "outputId": "3f2e8e6f-80c1-4ae8-e3c1-0706ac3b5635"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 298\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 39\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 38\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnrdD8pZoOPx",
        "outputId": "17d83507-cfc6-4597-b4ac-10b1e5f7243b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datasets.dataset_dict.DatasetDict"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hVunfNU68i0",
        "outputId": "1568829f-7cc4-4fe4-9eff-984ae17539eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'answer', 'requires_line', 'id'],\n",
              "    num_rows: 298\n",
              "})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6Daio0eONzd",
        "outputId": "e31a0091-8c9e-4181-e8d5-15b916412292"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAT READING COMPREHENSION TEST\n",
            "\n",
            "This passage is adapted from George Eliot, Silas Marner.\n",
            "Originally published in 1861. Silas was a weaver and a\n",
            "notorious miser, but then the gold he had hoarded was\n",
            "stolen. Shortly after, Silas adopted a young child, Eppie, the\n",
            "daughter of an impoverished woman who had died\n",
            "suddenly.\n",
            "\n",
            "    Unlike the gold which needed nothing, and must\n",
            "be worshipped in close-locked solitude—which was\n",
            "hidden away from the daylight, was deaf to the song\n",
            "of birds, and started to no human tones—Eppie was a\n",
            "creature of endless claims and ever-growing desires,\n",
            "seeking and loving sunshine, and living sounds, and\n",
            "living movements; making trial of everything, with\n",
            "trust in new joy, and stirring the human kindness in\n",
            "all eyes that looked on her. The gold had kept his\n",
            "thoughts in an ever-repeated circle, leading to\n",
            "nothing beyond itself; but Eppie was an object\n",
            "compacted of changes and hopes that forced his\n",
            "thoughts onward, and carried them far away from\n",
            "their old eager pacing towards the same blank\n",
            "limit—carried them away to the new things that\n",
            "would come with the coming years, when Eppie\n",
            "would have learned to understand how her father\n",
            "Silas cared for her; and made him look for images of\n",
            "that time in the ties and charities that bound together\n",
            "the families of his neighbors. The gold had asked that\n",
            "he should sit weaving longer and longer, deafened\n",
            "and blinded more and more to all things except the\n",
            "monotony of his loom and the repetition of his web;\n",
            "but Eppie called him away from his weaving, and\n",
            "made him think all its pauses a holiday, reawakening\n",
            "his senses with her fresh life, even to the old\n",
            "winter-flies that came crawling forth in the early\n",
            "spring sunshine, and warming him into joy because\n",
            "she had joy.\n",
            "    And when the sunshine grew strong and lasting,\n",
            "so that the buttercups were thick in the meadows,\n",
            "Silas might be seen in the sunny mid-day, or in the\n",
            "late afternoon when the shadows were lengthening\n",
            "under the hedgerows, strolling out with uncovered\n",
            "head to carry Eppie beyond the Stone-pits to where\n",
            "the flowers grew, till they reached some favorite bank\n",
            "where he could sit down, while Eppie toddled to\n",
            "pluck the flowers, and make remarks to the winged\n",
            "things that murmured happily above the bright\n",
            "petals, calling “Dad-dad’s” attention continually by\n",
            "bringing him the flowers. Then she would turn her\n",
            "ear to some sudden bird-note, and Silas learned to\n",
            "please her by making signs of hushed stillness, that\n",
            "they might listen for the note to come again: so that\n",
            "when it came, she set up her small back and laughed\n",
            "with gurgling triumph. Sitting on the banks in this\n",
            "way, Silas began to look for the once familiar herbs\n",
            "again; and as the leaves, with their unchanged outline\n",
            "and markings, lay on his palm, there was a sense of\n",
            "crowding remembrances from which he turned away\n",
            "timidly, taking refuge in Eppie’s little world, that lay\n",
            "lightly on his enfeebled spirit.\n",
            "    As the child’s mind was growing into knowledge,\n",
            "his mind was growing into memory: as her life\n",
            "unfolded, his soul, long stupefied in a cold narrow\n",
            "prison, was unfolding too, and trembling gradually\n",
            "into full consciousness.\n",
            "    It was an influence which must gather force with\n",
            "every new year: the tones that stirred Silas’ heart\n",
            "grew articulate, and called for more distinct answers;\n",
            "shapes and sounds grew clearer for Eppie’s eyes and\n",
            "ears, and there was more that “Dad-dad” was\n",
            "imperatively required to notice and account for.\n",
            "Also, by the time Eppie was three years old, she\n",
            "developed a fine capacity for mischief, and for\n",
            "devising ingenious ways of being troublesome, which\n",
            "found much exercise, not only for Silas’ patience, but\n",
            "for his watchfulness and penetration. Sorely was poor\n",
            "Silas puzzled on such occasions by the incompatible\n",
            "demands of love.\n",
            "\n",
            "\n",
            "\n",
            "Question 4:\n",
            "The narrator uses the phrase “making trial of everything” (line 7) to present Eppie as\n",
            "A) friendly.\n",
            "B) curious.\n",
            "C) disobedient.\n",
            "D) judgmental.\n",
            "\n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "print(data[\"train\"][\"text\"][4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0UKWAUSMAsH",
        "outputId": "64644985-7482-4117-a5f8-a8bdd37fa18b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "B\n"
          ]
        }
      ],
      "source": [
        "print(data[\"train\"][\"answer\"][4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRZPr4jHP3xG"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def extract_sections(text):\n",
        "    \"\"\"Parse raw SAT text into structured sections\"\"\"\n",
        "    sections = {\"passage\": \"\", \"question\": \"\", \"choices\": [], \"answer_letter\": \"\"}\n",
        "\n",
        "    # Tách phần answer\n",
        "    match = re.search(r\"Answer:\\s*([A-E])\", text, re.IGNORECASE)\n",
        "    sections[\"answer_letter\"] = match.group(1) if match else \"\"\n",
        "\n",
        "    # Tách các phần chính\n",
        "    # Greedy matching with *\n",
        "    match = re.search(\n",
        "        r\"SAT READING COMPREHENSION TEST(.*)Answer:\", text, re.DOTALL | re.IGNORECASE\n",
        "    )\n",
        "    content = match.group(1).strip() if match else \"\"\n",
        "    blocks = [b.strip() for b in re.split(r\"\\n\\n\", content) if b.strip()]\n",
        "    sections[\"passage\"] = \"\\n\".join(blocks[0:2])\n",
        "    question_block = blocks[2].splitlines()\n",
        "    sections[\"question\"] = question_block[1]\n",
        "    sections[\"choices\"] = question_block[2:]\n",
        "\n",
        "    return sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvmFnZ7Quf7j",
        "outputId": "bef3dd7e-e53b-43a0-81c9-4c3abfb19b88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'passage': 'This passage is adapted from George Eliot, Silas Marner.\\nOriginally published in 1861. Silas was a weaver and a\\nnotorious miser, but then the gold he had hoarded was\\nstolen. Shortly after, Silas adopted a young child, Eppie, the\\ndaughter of an impoverished woman who had died\\nsuddenly.\\nUnlike the gold which needed nothing, and must\\nbe worshipped in close-locked solitude—which was\\nhidden away from the daylight, was deaf to the song\\nof birds, and started to no human tones—Eppie was a\\ncreature of endless claims and ever-growing desires,\\nseeking and loving sunshine, and living sounds, and\\nliving movements; making trial of everything, with\\ntrust in new joy, and stirring the human kindness in\\nall eyes that looked on her. The gold had kept his\\nthoughts in an ever-repeated circle, leading to\\nnothing beyond itself; but Eppie was an object\\ncompacted of changes and hopes that forced his\\nthoughts onward, and carried them far away from\\ntheir old eager pacing towards the same blank\\nlimit—carried them away to the new things that\\nwould come with the coming years, when Eppie\\nwould have learned to understand how her father\\nSilas cared for her; and made him look for images of\\nthat time in the ties and charities that bound together\\nthe families of his neighbors. The gold had asked that\\nhe should sit weaving longer and longer, deafened\\nand blinded more and more to all things except the\\nmonotony of his loom and the repetition of his web;\\nbut Eppie called him away from his weaving, and\\nmade him think all its pauses a holiday, reawakening\\nhis senses with her fresh life, even to the old\\nwinter-flies that came crawling forth in the early\\nspring sunshine, and warming him into joy because\\nshe had joy.\\n    And when the sunshine grew strong and lasting,\\nso that the buttercups were thick in the meadows,\\nSilas might be seen in the sunny mid-day, or in the\\nlate afternoon when the shadows were lengthening\\nunder the hedgerows, strolling out with uncovered\\nhead to carry Eppie beyond the Stone-pits to where\\nthe flowers grew, till they reached some favorite bank\\nwhere he could sit down, while Eppie toddled to\\npluck the flowers, and make remarks to the winged\\nthings that murmured happily above the bright\\npetals, calling “Dad-dad’s” attention continually by\\nbringing him the flowers. Then she would turn her\\near to some sudden bird-note, and Silas learned to\\nplease her by making signs of hushed stillness, that\\nthey might listen for the note to come again: so that\\nwhen it came, she set up her small back and laughed\\nwith gurgling triumph. Sitting on the banks in this\\nway, Silas began to look for the once familiar herbs\\nagain; and as the leaves, with their unchanged outline\\nand markings, lay on his palm, there was a sense of\\ncrowding remembrances from which he turned away\\ntimidly, taking refuge in Eppie’s little world, that lay\\nlightly on his enfeebled spirit.\\n    As the child’s mind was growing into knowledge,\\nhis mind was growing into memory: as her life\\nunfolded, his soul, long stupefied in a cold narrow\\nprison, was unfolding too, and trembling gradually\\ninto full consciousness.\\n    It was an influence which must gather force with\\nevery new year: the tones that stirred Silas’ heart\\ngrew articulate, and called for more distinct answers;\\nshapes and sounds grew clearer for Eppie’s eyes and\\nears, and there was more that “Dad-dad” was\\nimperatively required to notice and account for.\\nAlso, by the time Eppie was three years old, she\\ndeveloped a fine capacity for mischief, and for\\ndevising ingenious ways of being troublesome, which\\nfound much exercise, not only for Silas’ patience, but\\nfor his watchfulness and penetration. Sorely was poor\\nSilas puzzled on such occasions by the incompatible\\ndemands of love.',\n",
              " 'question': 'The narrator uses the phrase “making trial of everything” (line 7) to present Eppie as',\n",
              " 'choices': ['A) friendly.',\n",
              "  'B) curious.',\n",
              "  'C) disobedient.',\n",
              "  'D) judgmental.'],\n",
              " 'answer_letter': ''}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extract_sections(data[\"train\"][\"text\"][4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcnc_sHKP3xH"
      },
      "outputs": [],
      "source": [
        "def map_answer(text, letter):\n",
        "    \"\"\"Match answer letter with full choice text\"\"\"\n",
        "    sections = extract_sections(text)\n",
        "    for choice in sections[\"choices\"]:\n",
        "        if choice.startswith(f\"{letter})\"):\n",
        "            return choice\n",
        "    return letter  # Fallback if not found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMxfJFHEv8J7"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(text, answer_letter):\n",
        "    sections = extract_sections(text)\n",
        "\n",
        "    choices_text = \"\\n\".join(sections[\"choices\"])\n",
        "\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": LLAMA3_SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Read the passage and answer the question.\n",
        "\n",
        "### Passage:\n",
        "{sections['passage']}\n",
        "\n",
        "### Question:\n",
        "{sections['question']}\n",
        "\n",
        "### Choices:\n",
        "{choices_text}\n",
        "\n",
        "Respond with ONLY the letter and full text of the correct answer.\"\"\",\n",
        "        },\n",
        "        {\"role\": \"assistant\", \"content\": map_answer(text, answer_letter)},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-GbfsEOZ-T_"
      },
      "outputs": [],
      "source": [
        "def generate_and_tokenize_prompt(user_input, answer):\n",
        "    try:\n",
        "        full_prompt = generate_prompt(user_input, answer)\n",
        "\n",
        "        prompt_str = tokenizer.apply_chat_template(\n",
        "            full_prompt, tokenize=False, add_generation_prompt=False\n",
        "        )\n",
        "        tokenized = tokenizer(\n",
        "            prompt_str,\n",
        "            # padding=\"max_length\",\n",
        "            # truncation=True,\n",
        "            # max_length=1500,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        input_ids = tokenized[\"input_ids\"][0]\n",
        "        # labels = input_ids.clone()\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": tokenized[\"attention_mask\"][0],\n",
        "            # \"labels\": labels,\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing sample: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzkPgPviP3xH",
        "outputId": "81d5a19b-c4d3-4634-dd7a-55dd970e7b69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Generated Prompt ===\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 05 May 2025\n",
            "\n",
            "You are a helpful AI assistant developed by Meta. Respond safely and accurately.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Read the passage and answer the question.\n",
            "\n",
            "### Passage:\n",
            "This passage is adapted from George Eliot, Silas Marner.\n",
            "Originally published in 1861. Silas was a weaver and a\n",
            "notorious miser, but then the gold he had hoarded was\n",
            "stolen. Shortly after, Silas adopted a young child, Eppie, the\n",
            "daughter of an impoverished woman who had died\n",
            "suddenly.\n",
            "Unlike the gold which needed nothing, and must\n",
            "be worshipped in close-locked solitude—which was\n",
            "hidden away from the daylight, was deaf to the song\n",
            "of birds, and started to no human tones—Eppie was a\n",
            "creature of endless claims and ever-growing desires,\n",
            "seeking and loving sunshine, and living sounds, and\n",
            "living movements; making trial of everything, with\n",
            "trust in new joy, and stirring the human kindness in\n",
            "all eyes that looked on her. The gold had kept his\n",
            "thoughts in an ever-repeated circle, leading to\n",
            "nothing beyond itself; but Eppie was an object\n",
            "compacted of changes and hopes that forced his\n",
            "thoughts onward, and carried them far away from\n",
            "their old eager pacing towards the same blank\n",
            "limit—carried them away to the new things that\n",
            "would come with the coming years, when Eppie\n",
            "would have learned to understand how her father\n",
            "Silas cared for her; and made him look for images of\n",
            "that time in the ties and charities that bound together\n",
            "the families of his neighbors. The gold had asked that\n",
            "he should sit weaving longer and longer, deafened\n",
            "and blinded more and more to all things except the\n",
            "monotony of his loom and the repetition of his web;\n",
            "but Eppie called him away from his weaving, and\n",
            "made him think all its pauses a holiday, reawakening\n",
            "his senses with her fresh life, even to the old\n",
            "winter-flies that came crawling forth in the early\n",
            "spring sunshine, and warming him into joy because\n",
            "she had joy.\n",
            "    And when the sunshine grew strong and lasting,\n",
            "so that the buttercups were thick in the meadows,\n",
            "Silas might be seen in the sunny mid-day, or in the\n",
            "late afternoon when the shadows were lengthening\n",
            "under the hedgerows, strolling out with uncovered\n",
            "head to carry Eppie beyond the Stone-pits to where\n",
            "the flowers grew, till they reached some favorite bank\n",
            "where he could sit down, while Eppie toddled to\n",
            "pluck the flowers, and make remarks to the winged\n",
            "things that murmured happily above the bright\n",
            "petals, calling “Dad-dad’s” attention continually by\n",
            "bringing him the flowers. Then she would turn her\n",
            "ear to some sudden bird-note, and Silas learned to\n",
            "please her by making signs of hushed stillness, that\n",
            "they might listen for the note to come again: so that\n",
            "when it came, she set up her small back and laughed\n",
            "with gurgling triumph. Sitting on the banks in this\n",
            "way, Silas began to look for the once familiar herbs\n",
            "again; and as the leaves, with their unchanged outline\n",
            "and markings, lay on his palm, there was a sense of\n",
            "crowding remembrances from which he turned away\n",
            "timidly, taking refuge in Eppie’s little world, that lay\n",
            "lightly on his enfeebled spirit.\n",
            "    As the child’s mind was growing into knowledge,\n",
            "his mind was growing into memory: as her life\n",
            "unfolded, his soul, long stupefied in a cold narrow\n",
            "prison, was unfolding too, and trembling gradually\n",
            "into full consciousness.\n",
            "    It was an influence which must gather force with\n",
            "every new year: the tones that stirred Silas’ heart\n",
            "grew articulate, and called for more distinct answers;\n",
            "shapes and sounds grew clearer for Eppie’s eyes and\n",
            "ears, and there was more that “Dad-dad” was\n",
            "imperatively required to notice and account for.\n",
            "Also, by the time Eppie was three years old, she\n",
            "developed a fine capacity for mischief, and for\n",
            "devising ingenious ways of being troublesome, which\n",
            "found much exercise, not only for Silas’ patience, but\n",
            "for his watchfulness and penetration. Sorely was poor\n",
            "Silas puzzled on such occasions by the incompatible\n",
            "demands of love.\n",
            "\n",
            "### Question:\n",
            "Which statement best describes a technique the narrator uses to represent Silas’s character before he adopted Eppie?\n",
            "\n",
            "### Choices:\n",
            "A) The narrator emphasizes Silas’s former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
            "B) The narrator underscores Silas’s former greed by describing his gold as seeming to reproduce on its own.\n",
            "C) The narrator hints at Silas’s former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
            "D) The narrator demonstrates Silas’s former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
            "\n",
            "Respond with ONLY the letter and full text of the correct answer.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "A) The narrator emphasizes Silas’s former obsession with wealth by depicting his gold as requiring certain behaviors on his part.<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "sample_text = data[\"train\"][\"text\"][0]\n",
        "sample_answer = data[\"train\"][\"answer\"][0]\n",
        "\n",
        "example_messages = generate_prompt(sample_text, sample_answer)\n",
        "prompt_text = tokenizer.apply_chat_template(\n",
        "    example_messages, tokenize=False, add_generation_prompt=False\n",
        ")\n",
        "print(\"=== Generated Prompt ===\")\n",
        "print(prompt_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54rwNsHCaTJL",
        "outputId": "a7e24e8c-9917-48b5-db39-ab640246c72c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Tokenized Sample ===\n",
            "Input IDs shape: torch.Size([1124])\n",
            "Sample decoded back:\n",
            "system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 05 May 2025\n",
            "\n",
            "You are a helpful AI assistant developed by Meta. Respond safely and accurately.user\n",
            "\n",
            "Read the passage and answer the question.\n",
            "\n",
            "### Passage:\n",
            "This passage is adapted from George Eliot, Silas Marner.\n",
            "Originally published in 1861. Silas was a weaver and a\n",
            "notorious miser, but then the gold he had hoarded was\n",
            "stolen. Shortly after, Silas adopted a young child, Eppie, the\n",
            "daughter of an impoverished woman who had died\n",
            "suddenly.\n",
            "Unlike the gold which needed nothing, and must\n",
            "be worshipped in close-locked solitude—which was\n",
            "hidden away from the daylight, was deaf to the song\n",
            "of birds, and started to no human tones—Eppie was a\n",
            "creature of endless claims and ever-growing desires,\n",
            "seeking and loving sunshine, and living sounds, and\n",
            "living movements; making trial of everything, with\n",
            "trust in new joy, and stirring the human kindness in\n",
            "all eyes that looked on her. The gold had kept his\n",
            "thoughts in an ever-repeated circle, leading to\n",
            "nothing beyond itself; but Eppie was an object\n",
            "compacted of changes and hopes that forced his\n",
            "thoughts onward, and carried them far away from\n",
            "their old eager pacing towards the same blank\n",
            "limit—carried them away to the new things that\n",
            "would come with the coming years, when Eppie\n",
            "would have learned to understand how her father\n",
            "Silas cared for her; and made him look for images of\n",
            "that time in the ties and charities that bound together\n",
            "the families of his neighbors. The gold had asked that\n",
            "he should sit weaving longer and longer, deafened\n",
            "and blinded more and more to all things except the\n",
            "monotony of his loom and the repetition of his web;\n",
            "but Eppie called him away from his weaving, and\n",
            "made him think all its pauses a holiday, reawakening\n",
            "his senses with her fresh life, even to the old\n",
            "winter-flies that came crawling forth in the early\n",
            "spring sunshine, and warming him into joy because\n",
            "she had joy.\n",
            "    And when the sunshine grew strong and lasting,\n",
            "so that the buttercups were thick in the meadows,\n",
            "Silas might be seen in the sunny mid-day, or in the\n",
            "late afternoon when the shadows were lengthening\n",
            "under the hedgerows, strolling out with uncovered\n",
            "head to carry Eppie beyond the Stone-pits to where\n",
            "the flowers grew, till they reached some favorite bank\n",
            "where he could sit down, while Eppie toddled to\n",
            "pluck the flowers, and make remarks to the winged\n",
            "things that murmured happily above the bright\n",
            "petals, calling “Dad-dad’s” attention continually by\n",
            "bringing him the flowers. Then she would turn her\n",
            "ear to some sudden bird-note, and Silas learned to\n",
            "please her by making signs of hushed stillness, that\n",
            "they might listen for the note to come again: so that\n",
            "when it came, she set up her small back and laughed\n",
            "with gurgling triumph. Sitting on the banks in this\n",
            "way, Silas began to look for the once familiar herbs\n",
            "again; and as the leaves, with their unchanged outline\n",
            "and markings, lay on his palm, there was a sense of\n",
            "crowding remembrances from which he turned away\n",
            "timidly, taking refuge in Eppie’s little world, that lay\n",
            "lightly on his enfeebled spirit.\n",
            "    As the child’s mind was growing into knowledge,\n",
            "his mind was growing into memory: as her life\n",
            "unfolded, his soul, long stupefied in a cold narrow\n",
            "prison, was unfolding too, and trembling gradually\n",
            "into full consciousness.\n",
            "    It was an influence which must gather force with\n",
            "every new year: the tones that stirred Silas’ heart\n",
            "grew articulate, and called for more distinct answers;\n",
            "shapes and sounds grew clearer for Eppie’s eyes and\n",
            "ears, and there was more that “Dad-dad” was\n",
            "imperatively required to notice and account for.\n",
            "Also, by the time Eppie was three years old, she\n",
            "developed a fine capacity for mischief, and for\n",
            "devising ingenious ways of being troublesome, which\n",
            "found much exercise, not only for Silas’ patience, but\n",
            "for his watchfulness and penetration. Sorely was poor\n",
            "Silas puzzled on such occasions by the incompatible\n",
            "demands of love.\n",
            "\n",
            "### Question:\n",
            "Which statement best describes a technique the narrator uses to represent Silas’s character before he adopted Eppie?\n",
            "\n",
            "### Choices:\n",
            "A) The narrator emphasizes Silas’s former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
            "B) The narrator underscores Silas’s former greed by describing his gold as seeming to reproduce on its own.\n",
            "C) The narrator hints at Silas’s former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
            "D) The narrator demonstrates Silas’s former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
            "\n",
            "Respond with ONLY the letter and full text of the correct answer.assistant\n",
            "\n",
            "A) The narrator emphasizes Silas’s former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n"
          ]
        }
      ],
      "source": [
        "tokenized_sample = generate_and_tokenize_prompt(sample_text, sample_answer)\n",
        "if tokenized_sample:\n",
        "    print(\"\\n=== Tokenized Sample ===\")\n",
        "    print(f\"Input IDs shape: {tokenized_sample['input_ids'].shape}\")\n",
        "    print(f\"Sample decoded back:\")\n",
        "    print(tokenizer.decode(tokenized_sample[\"input_ids\"], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r0MqHFVuf7j"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(sample):\n",
        "    tokenized_sample = None\n",
        "    try:\n",
        "        processed_text = sample[\"text\"]\n",
        "        processed_answer = map_answer(sample[\"text\"], sample[\"answer\"].strip())\n",
        "        tokenized_sample = generate_and_tokenize_prompt(\n",
        "            processed_text, processed_answer\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping invalid sample: {e}\")\n",
        "    return tokenized_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgOfY_INuf7j"
      },
      "outputs": [],
      "source": [
        "dataset = data.map(\n",
        "    preprocess_dataset,\n",
        "    remove_columns=data[\"train\"].column_names,\n",
        "    num_proc=4,\n",
        "    desc=\"Processing training dataset\",\n",
        ").filter(\n",
        "    lambda x: x is not None,\n",
        "    desc=\"Filtering out invalid samples\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfl4NmyLuf7j",
        "outputId": "b0bbcee9-6e09-41d9-e29d-c5c19ba6604b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 298\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 39\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 38\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaPiMgsl78ol",
        "outputId": "21888139-075b-4555-d830-c981e321b0a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min: 864, Max: 1396, Avg: 1128.0\n"
          ]
        }
      ],
      "source": [
        "# check length samples\n",
        "train_lengths = [len(x[\"input_ids\"]) for x in dataset[\"train\"]]  # type: ignore\n",
        "eval_lengths = [len(x[\"input_ids\"]) for x in dataset[\"validation\"]]  # type: ignore\n",
        "all_lengths = train_lengths + eval_lengths\n",
        "print(\n",
        "    f\"Min: {min(all_lengths)}, Max: {max(all_lengths)}, Avg: {sum(all_lengths)/len(all_lengths):.1f}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcpuJU9_bDJu"
      },
      "source": [
        "### 4.2. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta_c_ISEP3xI"
      },
      "outputs": [],
      "source": [
        "from transformers.trainer_callback import TrainerCallback\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "\n",
        "\n",
        "class LogLossCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.console = Console()\n",
        "        self.table = Table(show_header=True, header_style=\"bold magenta\")\n",
        "        self.table.add_column(\"Step\", justify=\"right\")\n",
        "        self.table.add_column(\"Training Loss\", justify=\"right\")\n",
        "        # self.logged_steps = set()\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is not None and \"loss\" in logs:\n",
        "            step = state.global_step\n",
        "            loss = logs[\"loss\"]\n",
        "            self.table.add_row(str(step), f\"{loss:.6f}\")\n",
        "            # self.logged_steps.add(step)\n",
        "            self.console.clear()\n",
        "            self.console.print(self.table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgGMT5hruf7k",
        "outputId": "b566ebf8-cb3f-4643-b18b-9cb6453020cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaConfig {\n",
              "  \"_attn_implementation_autoset\": true,\n",
              "  \"architectures\": [\n",
              "    \"LlamaForCausalLM\"\n",
              "  ],\n",
              "  \"attention_bias\": false,\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 128000,\n",
              "  \"eos_token_id\": [\n",
              "    128001,\n",
              "    128008,\n",
              "    128009\n",
              "  ],\n",
              "  \"head_dim\": 128,\n",
              "  \"hidden_act\": \"silu\",\n",
              "  \"hidden_size\": 3072,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 8192,\n",
              "  \"max_position_embeddings\": 131072,\n",
              "  \"mlp_bias\": false,\n",
              "  \"model_type\": \"llama\",\n",
              "  \"num_attention_heads\": 24,\n",
              "  \"num_hidden_layers\": 28,\n",
              "  \"num_key_value_heads\": 8,\n",
              "  \"pretraining_tp\": 1,\n",
              "  \"quantization_config\": {\n",
              "    \"_load_in_4bit\": true,\n",
              "    \"_load_in_8bit\": false,\n",
              "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
              "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
              "    \"bnb_4bit_quant_type\": \"nf4\",\n",
              "    \"bnb_4bit_use_double_quant\": true,\n",
              "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
              "    \"llm_int8_has_fp16_weight\": false,\n",
              "    \"llm_int8_skip_modules\": null,\n",
              "    \"llm_int8_threshold\": 6.0,\n",
              "    \"load_in_4bit\": true,\n",
              "    \"load_in_8bit\": false,\n",
              "    \"quant_method\": \"bitsandbytes\"\n",
              "  },\n",
              "  \"rms_norm_eps\": 1e-05,\n",
              "  \"rope_scaling\": {\n",
              "    \"factor\": 32.0,\n",
              "    \"high_freq_factor\": 4.0,\n",
              "    \"low_freq_factor\": 1.0,\n",
              "    \"original_max_position_embeddings\": 8192,\n",
              "    \"rope_type\": \"llama3\"\n",
              "  },\n",
              "  \"rope_theta\": 500000.0,\n",
              "  \"tie_word_embeddings\": true,\n",
              "  \"torch_dtype\": \"float16\",\n",
              "  \"transformers_version\": \"4.52.0.dev0\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 128256\n",
              "}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpUOuw_Kuf7k",
        "outputId": "7accd253-ed37-4c3e-cca3-e4ab706e2931"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(peft.peft_model.PeftModelForCausalLM,\n",
              " peft.peft_model.PeftModel,\n",
              " transformers.utils.hub.PushToHubMixin,\n",
              " torch.nn.modules.module.Module,\n",
              " object)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from peft import PeftModelForCausalLM\n",
        "\n",
        "PeftModelForCausalLM.__mro__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dW973laKADUH"
      },
      "outputs": [],
      "source": [
        "from transformers.training_args import TrainingArguments\n",
        "from transformers.trainer import Trainer\n",
        "from transformers.data.data_collator import DataCollatorForLanguageModeling\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    save_total_limit=3,\n",
        "    logging_steps=10,\n",
        "    output_dir=\"llama3-8b-sat-reading\",\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.05,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"loss\",\n",
        "    greater_is_better=False,\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=False, pad_to_multiple_of=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RqJV3qj-uf7k",
        "outputId": "aac9f3e4-5f2c-477c-bd2d-e487cdad2e8e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='298' max='298' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [298/298 16:17, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.890500</td>\n",
              "      <td>2.283045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.972600</td>\n",
              "      <td>2.747153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.346200</td>\n",
              "      <td>3.182998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.159300</td>\n",
              "      <td>3.297653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.089700</td>\n",
              "      <td>3.482907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "│  240 │      0.099600 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "│  240 │      0.099600 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "│  240 │      0.099600 │\n",
              "│  250 │      0.089700 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "│  240 │      0.099600 │\n",
              "│  250 │      0.089700 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "│  240 │      0.099600 │\n",
              "│  250 │      0.089700 │\n",
              "│  260 │      0.102900 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "│  240 │      0.099600 │\n",
              "│  250 │      0.089700 │\n",
              "│  260 │      0.102900 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "│  240 │      0.099600 │\n",
              "│  250 │      0.089700 │\n",
              "│  260 │      0.102900 │\n",
              "│  270 │      0.118800 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "│  240 │      0.099600 │\n",
              "│  250 │      0.089700 │\n",
              "│  260 │      0.102900 │\n",
              "│  270 │      0.118800 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "│  240 │      0.099600 │\n",
              "│  250 │      0.089700 │\n",
              "│  260 │      0.102900 │\n",
              "│  270 │      0.118800 │\n",
              "│  280 │      0.099100 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "│  240 │      0.099600 │\n",
              "│  250 │      0.089700 │\n",
              "│  260 │      0.102900 │\n",
              "│  270 │      0.118800 │\n",
              "│  280 │      0.099100 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Step </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Training Loss </span>┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "│  240 │      0.099600 │\n",
              "│  250 │      0.089700 │\n",
              "│  260 │      0.102900 │\n",
              "│  270 │      0.118800 │\n",
              "│  280 │      0.099100 │\n",
              "│  290 │      0.153400 │\n",
              "└──────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35mStep\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mTraining Loss\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│   10 │      2.673300 │\n",
              "│   20 │      2.391900 │\n",
              "│   30 │      2.074300 │\n",
              "│   40 │      2.060700 │\n",
              "│   50 │      1.890500 │\n",
              "│   60 │      1.746800 │\n",
              "│   70 │      1.518500 │\n",
              "│   80 │      1.269200 │\n",
              "│   90 │      1.156400 │\n",
              "│  100 │      0.972600 │\n",
              "│  110 │      0.820500 │\n",
              "│  120 │      0.729500 │\n",
              "│  130 │      0.716800 │\n",
              "│  140 │      0.587800 │\n",
              "│  150 │      0.346200 │\n",
              "│  160 │      0.219300 │\n",
              "│  170 │      0.207400 │\n",
              "│  180 │      0.218000 │\n",
              "│  190 │      0.222900 │\n",
              "│  200 │      0.159300 │\n",
              "│  210 │      0.099900 │\n",
              "│  220 │      0.138900 │\n",
              "│  230 │      0.087700 │\n",
              "│  240 │      0.099600 │\n",
              "│  250 │      0.089700 │\n",
              "│  260 │      0.102900 │\n",
              "│  270 │      0.118800 │\n",
              "│  280 │      0.099100 │\n",
              "│  290 │      0.153400 │\n",
              "└──────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=298, training_loss=0.7733494035349596, metrics={'train_runtime': 980.7068, 'train_samples_per_second': 0.608, 'train_steps_per_second': 0.304, 'total_flos': 1.151508038909952e+16, 'train_loss': 0.7733494035349596, 'epoch': 2.0})"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Quantization-aware training settings\n",
        "model.config.use_cache = False\n",
        "model.enable_input_require_grads()\n",
        "# compiled_model = torch.compile(model)\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    callbacks=[LogLossCallback()],\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgFsBEbnIUw-"
      },
      "source": [
        "### 4.3. Test prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3J4kyeKeQ8B",
        "outputId": "f1b84f9e-1be5-49be-e2c5-1cdfe36aa5a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAT READING COMPREHENSION TEST\n",
            "\n",
            "This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "\n",
            "    Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She stepped off the train wearing a\n",
            "pair of thick-soled boots suitable for hiking, a navy\n",
            "Line blue dress, and a little white tam that rode the waves\n",
            "of her red hair at a gravity-defying angle. August was\n",
            "a hellish month to step off the train in Georgia,\n",
            "although it was nothing, she said, compared to the\n",
            "119 degrees that greeted her when she arrived one\n",
            "time in Timbuktu, which, she assured us, was a real\n",
            "place in Africa. I believe her remark irritated some of\n",
            "the people gathered to welcome her on the burned\n",
            "grass alongside the tracks. When folks are sweating\n",
            "through their shorts, they don’t like to hear that this\n",
            "is nothing compared to someplace else. Irritated or\n",
            "not, the majority of those present were inclined to see\n",
            "the arrival of the new schoolteacher in a positive\n",
            "light. Hard times were still upon us in 1938, but, like\n",
            "my momma said, “We weren’t no poorer than we’d\n",
            "ever been,” and the citizens of Threestep were in the\n",
            "mood for a little excitement.\n",
            "   Miss Spivey looked like just the right person to\n",
            "give it to them. She was, by almost anyone’s\n",
            "standards, a woman of the world. She’d gone to\n",
            "boarding schools since she was six years old; she’d\n",
            "studied French in Paris and drama in London; and\n",
            "during what she called a “fruitful intermission” in her\n",
            "formal education, she had traveled extensively in the\n",
            "Near East and Africa with a friend of her\n",
            "grandmother’s, one Janet Miller, who was a medical\n",
            "doctor from Nashville, Tennessee. After her travels\n",
            "with Dr. Miller, Miss Spivey continued her education\n",
            "by attending Barnard College in New York City. She\n",
            "told us all that at school the first day. When my little\n",
            "brother Ralphord asked what did she study at\n",
            "Barnyard College, Miss Spivey explained that\n",
            "Barnard, which she wrote on the blackboard, was the\n",
            "sister school of Columbia University, of which, she\n",
            "expected, we all had heard.\n",
            "    It was there, she told us, in the midst of trying to\n",
            "find her true mission in life, that she wandered one\n",
            "afternoon into a lecture by the famous John Dewey,\n",
            "who was talking about his famous book, Democracy\n",
            "and Education. Professor Dewey was in his seventies\n",
            "by then, Miss Spivey said, but he still liked to chat\n",
            "with students after a lecture—especially female\n",
            "students, she added—sometimes over coffee, and see\n",
            "in their eyes the fire his words could kindle. It was\n",
            "after this lecture and subsequent coffee that Miss\n",
            "Spivey had marched to the Teacher’s College and\n",
            "signed up, all aflame. Two years later, she told a\n",
            "cheery blue-suited woman from the WPA1 that she\n",
            "wanted to bring democracy and education to the\n",
            "poorest, darkest, most remote and forgotten corner\n",
            "of America.\n",
            "    They sent her to Threestep, Georgia.\n",
            "    Miss Spivey paused there for questions, avoiding\n",
            "my brother Ralphord’s eye.\n",
            "    What we really wanted to know about—all\n",
            "twenty-six of us across seven grade levels in the one\n",
            "room—was the pearly white button hanging on a\n",
            "string in front of the blackboard behind the teacher’s\n",
            "desk up front. That button on a string was something\n",
            "new. When Mavis Davis (the only bona fide seventh\n",
            "grader, at age thirteen) asked what it was for, Miss\n",
            "Spivey gave the string a tug, and to our astonishment,\n",
            "the whole world—or at least a wrinkled map of\n",
            "it—unfolded before our eyes. Her predecessor, Miss\n",
            "Chandler, had never once made use of that map,\n",
            "which was older than our fathers, and until that\n",
            "moment, not a one of us knew it was there.\n",
            "    Miss Spivey showed us on the map how she and\n",
            "Dr. Janet Miller had sailed across the Atlantic Ocean\n",
            "and past the Rock of Gibraltar into the\n",
            "Mediterranean Sea. Using the end of a ruler, she\n",
            "gently tapped such places as Morocco and Tunis and\n",
            "Algiers to mark their route along the top of Africa.\n",
            "They spent twenty hours on the train to Baghdad, she\n",
            "said, swathed in veils against the sand that crept in\n",
            "every crack and crevice.\n",
            "    “And can you guess what we saw from the train?”\n",
            "Miss Spivey asked. We could not. “Camels!” she said.\n",
            "“We saw a whole caravan of camels.” She looked\n",
            "around the room, waiting for us to be amazed and\n",
            "delighted at the thought.\n",
            "    We all hung there for a minute, thinking hard,\n",
            "until Mavis Davis spoke up.\n",
            "    “She means like the three kings rode to\n",
            "Bethlehem,” Mavis said, and she folded her hands\n",
            "smugly on her seventh-grade desk in the back of the\n",
            "room.\n",
            "    Miss Spivey made a mistake right then. Instead of\n",
            "beaming upon Mavis the kind of congratulatory\n",
            "smile that old Miss Chandler would have bestowed\n",
            "on her for having enlightened the rest of us, Miss\n",
            "Spivey simply said, “That’s right.”\n",
            "\n",
            "\n",
            "\n",
            "Question 7:\n",
            "In the third paragraph, what is the narrator most likely suggesting by describing Miss Spivey as having “wandered” (line 40) in one situation and “marched” (line 49) in another situation?\n",
            "A) Dewey, knowing Miss Spivey wasn’t very confident in her ability to teach, instilled in her a sense of determination.\n",
            "B) Talking with Dewey over coffee made Miss Spivey realize how excited she was to teach in the poorest, most remote corner of America.\n",
            "C) After two years spent studying, Miss Spivey was anxious to start teaching and be in charge of her own classroom.\n",
            "D) Miss Spivey’s initial encounter with Dewey’s ideas was somewhat accidental but ultimately motivated her to decisive action.\n",
            "\n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "print(data[\"test\"][\"text\"][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT3R6GyPP3xJ",
        "outputId": "8baf9124-cbda-4429-d77d-5195979bffbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ground truth:  D\n"
          ]
        }
      ],
      "source": [
        "print(\"Ground truth: \", data[\"test\"][\"answer\"][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWMAVb2qfDqj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import re\n",
        "from transformers import GenerationConfig\n",
        "\n",
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=64,\n",
        "    # temperature=0.0,\n",
        "    top_p=1.0,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.0,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "\n",
        "\n",
        "def extract_answer(output_text):\n",
        "    if \"<|assistant|>\" in output_text:\n",
        "        answer_part = output_text.split(\"<|assistant|>\")[-1].strip()\n",
        "    else:\n",
        "        answer_part = output_text.split(\"assistant\")[-1].strip()\n",
        "\n",
        "    match = re.search(r\"^([A-D])\\)\\s*([^\\n\\(]+)\", answer_part, re.MULTILINE)\n",
        "\n",
        "    if match:\n",
        "        return f\"{match.group(1)}) {match.group(2).strip()}\"\n",
        "    else:\n",
        "        clean_lines = [\n",
        "            line for line in answer_part.split(\"\\n\") if not line.startswith(\"**\")\n",
        "        ]\n",
        "        return clean_lines[0].strip() if clean_lines else answer_part\n",
        "\n",
        "\n",
        "def format_test_prompt(text, answer_letter=None):\n",
        "    \"\"\"Format input text as chat conversation (for prediction or test)\"\"\"\n",
        "    sections = extract_sections(text)\n",
        "\n",
        "    # Build choices block\n",
        "    choices_text = \"\\n\".join(sections[\"choices\"])\n",
        "\n",
        "    user_prompt = f\"\"\"Read the passage and answer the question.\n",
        "\n",
        "### Passage:\n",
        "{sections['passage']}\n",
        "\n",
        "### Question:\n",
        "{sections['question']}\n",
        "\n",
        "### Choices:\n",
        "{choices_text}\n",
        "\n",
        "Respond with ONLY the letter and full text of the correct answer.\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": LLAMA3_SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        "\n",
        "    if answer_letter:\n",
        "        messages.append(\n",
        "            {\"role\": \"assistant\", \"content\": map_answer(text, answer_letter)}\n",
        "        )\n",
        "\n",
        "    return messages\n",
        "\n",
        "\n",
        "def predict(text):\n",
        "    messages = format_test_prompt(text)\n",
        "\n",
        "    prompt_text = tokenizer.apply_chat_template(\n",
        "        messages, add_generation_prompt=False, tokenize=False\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "\n",
        "    # Decode\n",
        "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Only answer\n",
        "    return extract_answer(output_text), output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwRjpKXOP3xR",
        "outputId": "c57dfa32-949c-449c-f3f6-05ceeb14c0a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Final Result ===\n",
            "[Model Prediction]\n",
            "B) small rural town.\n",
            "\n",
            "[Ground Truth]\n",
            "B) small rural town.\n",
            "\n",
            "[Output Text]\n",
            "system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 05 May 2025\n",
            "\n",
            "You are a helpful AI assistant developed by Meta. Respond safely and accurately.user\n",
            "\n",
            "Read the passage and answer the question.\n",
            "\n",
            "### Passage:\n",
            "This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She stepped off the train wearing a\n",
            "pair of thick-soled boots suitable for hiking, a navy\n",
            "Line blue dress, and a little white tam that rode the waves\n",
            "of her red hair at a gravity-defying angle. August was\n",
            "a hellish month to step off the train in Georgia,\n",
            "although it was nothing, she said, compared to the\n",
            "119 degrees that greeted her when she arrived one\n",
            "time in Timbuktu, which, she assured us, was a real\n",
            "place in Africa. I believe her remark irritated some of\n",
            "the people gathered to welcome her on the burned\n",
            "grass alongside the tracks. When folks are sweating\n",
            "through their shorts, they don’t like to hear that this\n",
            "is nothing compared to someplace else. Irritated or\n",
            "not, the majority of those present were inclined to see\n",
            "the arrival of the new schoolteacher in a positive\n",
            "light. Hard times were still upon us in 1938, but, like\n",
            "my momma said, “We weren’t no poorer than we’d\n",
            "ever been,” and the citizens of Threestep were in the\n",
            "mood for a little excitement.\n",
            "   Miss Spivey looked like just the right person to\n",
            "give it to them. She was, by almost anyone’s\n",
            "standards, a woman of the world. She’d gone to\n",
            "boarding schools since she was six years old; she’d\n",
            "studied French in Paris and drama in London; and\n",
            "during what she called a “fruitful intermission” in her\n",
            "formal education, she had traveled extensively in the\n",
            "Near East and Africa with a friend of her\n",
            "grandmother’s, one Janet Miller, who was a medical\n",
            "doctor from Nashville, Tennessee. After her travels\n",
            "with Dr. Miller, Miss Spivey continued her education\n",
            "by attending Barnard College in New York City. She\n",
            "told us all that at school the first day. When my little\n",
            "brother Ralphord asked what did she study at\n",
            "Barnyard College, Miss Spivey explained that\n",
            "Barnard, which she wrote on the blackboard, was the\n",
            "sister school of Columbia University, of which, she\n",
            "expected, we all had heard.\n",
            "    It was there, she told us, in the midst of trying to\n",
            "find her true mission in life, that she wandered one\n",
            "afternoon into a lecture by the famous John Dewey,\n",
            "who was talking about his famous book, Democracy\n",
            "and Education. Professor Dewey was in his seventies\n",
            "by then, Miss Spivey said, but he still liked to chat\n",
            "with students after a lecture—especially female\n",
            "students, she added—sometimes over coffee, and see\n",
            "in their eyes the fire his words could kindle. It was\n",
            "after this lecture and subsequent coffee that Miss\n",
            "Spivey had marched to the Teacher’s College and\n",
            "signed up, all aflame. Two years later, she told a\n",
            "cheery blue-suited woman from the WPA1 that she\n",
            "wanted to bring democracy and education to the\n",
            "poorest, darkest, most remote and forgotten corner\n",
            "of America.\n",
            "    They sent her to Threestep, Georgia.\n",
            "    Miss Spivey paused there for questions, avoiding\n",
            "my brother Ralphord’s eye.\n",
            "    What we really wanted to know about—all\n",
            "twenty-six of us across seven grade levels in the one\n",
            "room—was the pearly white button hanging on a\n",
            "string in front of the blackboard behind the teacher’s\n",
            "desk up front. That button on a string was something\n",
            "new. When Mavis Davis (the only bona fide seventh\n",
            "grader, at age thirteen) asked what it was for, Miss\n",
            "Spivey gave the string a tug, and to our astonishment,\n",
            "the whole world—or at least a wrinkled map of\n",
            "it—unfolded before our eyes. Her predecessor, Miss\n",
            "Chandler, had never once made use of that map,\n",
            "which was older than our fathers, and until that\n",
            "moment, not a one of us knew it was there.\n",
            "    Miss Spivey showed us on the map how she and\n",
            "Dr. Janet Miller had sailed across the Atlantic Ocean\n",
            "and past the Rock of Gibraltar into the\n",
            "Mediterranean Sea. Using the end of a ruler, she\n",
            "gently tapped such places as Morocco and Tunis and\n",
            "Algiers to mark their route along the top of Africa.\n",
            "They spent twenty hours on the train to Baghdad, she\n",
            "said, swathed in veils against the sand that crept in\n",
            "every crack and crevice.\n",
            "    “And can you guess what we saw from the train?”\n",
            "Miss Spivey asked. We could not. “Camels!” she said.\n",
            "“We saw a whole caravan of camels.” She looked\n",
            "around the room, waiting for us to be amazed and\n",
            "delighted at the thought.\n",
            "    We all hung there for a minute, thinking hard,\n",
            "until Mavis Davis spoke up.\n",
            "    “She means like the three kings rode to\n",
            "Bethlehem,” Mavis said, and she folded her hands\n",
            "smugly on her seventh-grade desk in the back of the\n",
            "room.\n",
            "    Miss Spivey made a mistake right then. Instead of\n",
            "beaming upon Mavis the kind of congratulatory\n",
            "smile that old Miss Chandler would have bestowed\n",
            "on her for having enlightened the rest of us, Miss\n",
            "Spivey simply said, “That’s right.”\n",
            "\n",
            "### Question:\n",
            "In the passage, Threestep is mainly presented as a\n",
            "\n",
            "### Choices:\n",
            "A) summer retreat for vacationers.\n",
            "B) small rural town.\n",
            "C) town that is home to a prominent university.\n",
            "D) comfortable suburb.\n",
            "\n",
            "Respond with ONLY the letter and full text of the correct answer.assistant\n",
            "\n",
            "B) small rural town.\n"
          ]
        }
      ],
      "source": [
        "test_sample_idx = 4\n",
        "input_text = data[\"test\"][\"text\"][test_sample_idx]\n",
        "true_answer = data[\"test\"][\"answer\"][test_sample_idx]\n",
        "\n",
        "predicted_answer, output_text = predict(input_text)\n",
        "\n",
        "true_answer_full = map_answer(input_text, true_answer)\n",
        "\n",
        "print(\"=== Final Result ===\")\n",
        "print(f\"[Model Prediction]\\n{predicted_answer}\")\n",
        "print(f\"\\n[Ground Truth]\\n{true_answer_full}\")\n",
        "print(f\"\\n[Output Text]\\n{output_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHAv8F09P3xR"
      },
      "source": [
        "## 5. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em6Nz3thP3xR",
        "outputId": "8fcd9157-e5e1-421a-dd2d-7e5b550985e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 38/38 [02:23<00:00,  3.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Evaluation Results ===\n",
            "Correct: 14/38\n",
            "Accuracy: 36.84%\n",
            "Wrong samples saved in 'wrong_samples' list\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def evaluate(test_dataset, max_samples=None):\n",
        "    \"\"\"\n",
        "    Evaluate model accuracy on test set\n",
        "    Args:\n",
        "        test_dataset: Dataset object containing 'text' and 'answer'\n",
        "        max_samples: Optional limit for quick testing\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    wrong_samples = []\n",
        "\n",
        "    # Process samples with progress bar\n",
        "    for idx in tqdm(range(len(test_dataset[:max_samples][\"text\"]))):\n",
        "        try:\n",
        "            text = test_dataset[\"text\"][idx]\n",
        "            true_answer = test_dataset[\"answer\"][idx].strip().upper()\n",
        "\n",
        "            # Get model prediction\n",
        "            predicted, _ = predict(text)\n",
        "\n",
        "            # Extract first valid choice letter from prediction\n",
        "            predicted_letter = re.search(r\"\\b([A-D])\\b\", predicted.upper())\n",
        "            if predicted_letter:\n",
        "                predicted_letter = predicted_letter.group(1)\n",
        "            else:\n",
        "                predicted_letter = None\n",
        "\n",
        "            # Compare with ground truth\n",
        "            if predicted_letter == true_answer:\n",
        "                correct += 1\n",
        "            else:\n",
        "                wrong_samples.append(\n",
        "                    {\"text\": text, \"predicted\": predicted, \"true\": true_answer}\n",
        "                )\n",
        "\n",
        "            total += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing sample {idx}: {str(e)}\")\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n=== Evaluation Results ===\")\n",
        "    print(f\"Correct: {correct}/{total}\")\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"Wrong samples saved in 'wrong_samples' list\")\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"total\": total, \"wrong_samples\": wrong_samples}\n",
        "\n",
        "\n",
        "# Usage\n",
        "test_results = evaluate(data[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JwEcHEmP3xS",
        "outputId": "d79428fc-6c48-420e-8c77-1eda3e575f75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Sample 1\n",
            "Ground Truth: D\n",
            "Predicted: A) sympathy, because they assume that she is experiencing intense heat for the first time.\n",
            "Passage:\n",
            "This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She steppe...\n",
            "\n",
            "--------------------------------------------------\n",
            "### Sample 2\n",
            "Ground Truth: A\n",
            "Predicted: C) an anonymous member of the community.\n",
            "Passage:\n",
            "This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She steppe...\n",
            "\n",
            "--------------------------------------------------\n",
            "### Sample 3\n",
            "Ground Truth: C\n",
            "Predicted: A) delighted.\n",
            "Passage:\n",
            "This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She steppe...\n",
            "\n",
            "--------------------------------------------------\n",
            "### Sample 4\n",
            "Ground Truth: C\n",
            "Predicted: D) Miss Chandler’s retirement from teaching.\n",
            "Passage:\n",
            "This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She steppe...\n",
            "\n",
            "--------------------------------------------------\n",
            "### Sample 5\n",
            "Ground Truth: C\n",
            "Predicted: D) The new transit system can have environmental value only if it is backed up by complementary reductions in car use.\n",
            "Passage:\n",
            "This passage is adapted from David Owen, The Conundrum:\n",
            "How Scientific Innovation, Increased Efficiency, and Good\n",
            "Intentions Can Make Our Energy and Climate Problems Worse.\n",
            "©2011 by David Owen.\n",
            "Buildi...\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i, sample in enumerate(test_results[\"wrong_samples\"][:5]):\n",
        "    print(f\"### Sample {i+1}\")\n",
        "    print(f\"Ground Truth: {sample['true']}\")\n",
        "    print(f\"Predicted: {sample['predicted']}\")\n",
        "    print(\"Passage:\")\n",
        "    print(extract_sections(sample[\"text\"])[\"passage\"][:200] + \"...\")\n",
        "    print(\"\\n\" + \"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9ZTFfNebJDK"
      },
      "source": [
        "## 6. Save model to huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIB19R50EzNZ"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"trained-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "8b1ed1dbbbd146e896a643f8ea965377",
            "bb5d90d0e5dc4f4bbcff3f85d57132dd",
            "f84659c158e44214b1b711643ad5bdba",
            "7de2d6241c60448d9e8bc8b757d3e0b4",
            "b87f346ed31b4679bcde5219e746d849",
            "ab02f88a674846f28d5a8aa70826b0ca",
            "72d0f71580d84a12aaba22181398ef40",
            "2057512d97e7496b9b8014d746361de9",
            "eac1a2b08e404fce9e5974e665b73fe6",
            "cc94d706de3540c6baf5a62fc4e8b741",
            "1a9755a097e943e49024f4044128c423",
            "4d1d6e49915445bdb823aff50e9f30d4",
            "b2bc133f01734215b09dd6eb7717b3db",
            "57edd5f5d0124f3580763b85509bdd58",
            "311621b37f79439088b7abb385217380",
            "640beb91f1dd4e5f90ce413cb2ae0030",
            "b913e29b6fdf4c9b84c4d0b1ce1b1638",
            "f35a2ff5ca1147c5b1f3f6bd6a229594",
            "5760a005a564413daf983eb827f7db82",
            "5c0a460e68534565b2271d196fa5ebb7",
            "2db0156ec7904d4db5e2f7768b97dacd",
            "3d549acaf94d44f6a650a1ce283637ff"
          ]
        },
        "id": "U7uZyfH6EzVc",
        "outputId": "1747cc81-27c1-4862-d737-fdd8fc5f0b7d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:907: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b1ed1dbbbd146e896a643f8ea965377",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d1d6e49915445bdb823aff50e9f30d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/97.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/tiviluson/Llama-3.2-3B-SAT/commit/d01ea047020b762afabd473947827cce07d34986', commit_message='Upload model', commit_description='', oid='d01ea047020b762afabd473947827cce07d34986', pr_url=None, repo_url=RepoUrl('https://huggingface.co/tiviluson/Llama-3.2-3B-SAT', endpoint='https://huggingface.co', repo_type='model', repo_id='tiviluson/Llama-3.2-3B-SAT'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PEFT_MODEL = \"tiviluson/Llama-3.2-3B-SAT\"\n",
        "\n",
        "model.push_to_hub(PEFT_MODEL, use_auth_token=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FofrEs3QIScD"
      },
      "source": [
        "## 7. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a1b83097ae9a47d3a55651b198547829",
            "d4a113278423487cb8618927e3852f6e",
            "ea0b24b47bd748f0beae109ea2f3a95a",
            "e1bb0bf97d4c49b4a3e98a1c191473ea",
            "fc9a8aed4be947129487baa24b2af408",
            "f21ed64b5b9b4a849d20a8f554ee8331",
            "f952f3d5b5e444f4b80bfe981a06b234",
            "25bc7c7d289f46da96ee633c7e2d39e8",
            "ab9b72df0fdf49fb8ed8f167b3ea11e5",
            "aa59ca189a174c1183c389c684eb1630",
            "44d033126bdf4c92848dfa5cfddb1713"
          ]
        },
        "id": "lxjoUMCcE0Sb",
        "outputId": "3bdeda28-fbac-450a-d0ab-cd22f56871d4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1b83097ae9a47d3a55651b198547829",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from peft import PeftConfig, PeftModel\n",
        "\n",
        "\n",
        "def format_inference_prompt(text):\n",
        "    sections = extract_sections(text)\n",
        "    choices_text = \"\\n\".join(sections[\"choices\"])\n",
        "\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": LLAMA3_SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Read the passage and answer the question.\n",
        "\n",
        "### Passage: {sections['passage']}\n",
        "### Question: {sections['question']}\n",
        "### Choices: {choices_text}\n",
        "\n",
        "Respond with ONLY the letter and full text of the correct answer.\"\"\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "\n",
        "PEFT_MODEL = \"tiviluson/Llama-3.2-3B-SAT\"\n",
        "\n",
        "# Load config v& model\n",
        "config = PeftConfig.from_pretrained(PEFT_MODEL)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name_or_path,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "model = PeftModel.from_pretrained(model, PEFT_MODEL)\n",
        "\n",
        "# Tokenizer & generation config\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=128,\n",
        "    # temperature=0.01,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.15,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    forced_eos_token_id=tokenizer.eos_token_id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfsLgcIkE2Qm",
        "outputId": "85a6efdc-7039-4a81-d001-a0b38e611813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "=== Sample 1 ===\n",
            "[Question]\n",
            "Read the passage and answer the question.\n",
            "\n",
            "### Passage: This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She stepped off the train wearing a\n",
            "pair of thick-soled boots suitable for hiking, a navy\n",
            "Line blue dress, and a little white tam that rode the waves\n",
            "of her red hair at a gravity-defying angle. August was\n",
            "a hellish month to step off the train in Georgia,\n",
            "although it was nothing, she said, compared to the\n",
            "119 degrees that greeted her when she arrived one\n",
            "time in Timbuktu, which, she assured us, was a real\n",
            "place in Africa. I believe her remark irritated some of\n",
            "the people gathered to welcome her on the burned\n",
            "grass alongside the tracks. When folks are sweating\n",
            "through their shorts, they don’t like to hear that this\n",
            "is nothing compared to someplace else. Irritated or\n",
            "not, the majority of those present were inclined to see\n",
            "the arrival of the new schoolteacher in a positive\n",
            "light. Hard times were still upon us in 1938, but, like\n",
            "my momma said, “We weren’t no poorer than we’d\n",
            "ever been,” and the citizens of Threestep were in the\n",
            "mood for a little excitement.\n",
            "   Miss Spivey looked like just the right person to\n",
            "give it to them. She was, by almost anyone’s\n",
            "standards, a woman of the world. She’d gone to\n",
            "boarding schools since she was six years old; she’d\n",
            "studied French in Paris and drama in London; and\n",
            "during what she called a “fruitful intermission” in her\n",
            "formal education, she had traveled extensively in the\n",
            "Near East and Africa with a friend of her\n",
            "grandmother’s, one Janet Miller, who was a medical\n",
            "doctor from Nashville, Tennessee. After her travels\n",
            "with Dr. Miller, Miss Spivey continued her education\n",
            "by attending Barnard College in New York City. She\n",
            "told us all that at school the first day. When my little\n",
            "brother Ralphord asked what did she study at\n",
            "Barnyard College, Miss Spivey explained that\n",
            "Barnard, which she wrote on the blackboard, was the\n",
            "sister school of Columbia University, of which, she\n",
            "expected, we all had heard.\n",
            "    It was there, she told us, in the midst of trying to\n",
            "find her true mission in life, that she wandered one\n",
            "afternoon into a lecture by the famous John Dewey,\n",
            "who was talking about his famous book, Democracy\n",
            "and Education. Professor Dewey was in his seventies\n",
            "by then, Miss Spivey said, but he still liked to chat\n",
            "with students after a lecture—especially female\n",
            "students, she added—sometimes over coffee, and see\n",
            "in their eyes the fire his words could kindle. It was\n",
            "after this lecture and subsequent coffee that Miss\n",
            "Spivey had marched to the Teacher’s College and\n",
            "signed up, all aflame. Two years later, she told a\n",
            "cheery blue-suited woman from the WPA1 that she\n",
            "wanted to bring democracy and education to the\n",
            "poorest, darkest, most remote and forgotten corner\n",
            "of America.\n",
            "    They sent her to Threestep, Georgia.\n",
            "    Miss Spivey paused there for questions, avoiding\n",
            "my brother Ralphord’s eye.\n",
            "    What we really wanted to know about—all\n",
            "twenty-six of us across seven grade levels in the one\n",
            "room—was the pearly white button hanging on a\n",
            "string in front of the blackboard behind the teacher’s\n",
            "desk up front. That button on a string was something\n",
            "new. When Mavis Davis (the only bona fide seventh\n",
            "grader, at age thirteen) asked what it was for, Miss\n",
            "Spivey gave the string a tug, and to our astonishment,\n",
            "the whole world—or at least a wrinkled map of\n",
            "it—unfolded before our eyes. Her predecessor, Miss\n",
            "Chandler, had never once made use of that map,\n",
            "which was older than our fathers, and until that\n",
            "moment, not a one of us knew it was there.\n",
            "    Miss Spivey showed us on the map how she and\n",
            "Dr. Janet Miller had sailed across the Atlantic Ocean\n",
            "and past the Rock of Gibraltar into the\n",
            "Mediterranean Sea. Using the end of a ruler, she\n",
            "gently tapped such places as Morocco and Tunis and\n",
            "Algiers to mark their route along the top of Africa.\n",
            "They spent twenty hours on the train to Baghdad, she\n",
            "said, swathed in veils against the sand that crept in\n",
            "every crack and crevice.\n",
            "    “And can you guess what we saw from the train?”\n",
            "Miss Spivey asked. We could not. “Camels!” she said.\n",
            "“We saw a whole caravan of camels.” She looked\n",
            "around the room, waiting for us to be amazed and\n",
            "delighted at the thought.\n",
            "    We all hung there for a minute, thinking hard,\n",
            "until Mavis Davis spoke up.\n",
            "    “She means like the three kings rode to\n",
            "Bethlehem,” Mavis said, and she folded her hands\n",
            "smugly on her seventh-grade desk in the back of the\n",
            "room.\n",
            "    Miss Spivey made a mistake right then. Instead of\n",
            "beaming upon Mavis the kind of congratulatory\n",
            "smile that old Miss Chandler would have bestowed\n",
            "on her for having enlightened the rest of us, Miss\n",
            "Spivey simply said, “That’s right.”\n",
            "### Question: It can reasonably be inferred from the passage that some of the people at the train station regard Miss Spivey’s comment about the Georgia heat with\n",
            "### Choices: A) sympathy, because they assume that she is experiencing intense heat for the first time.\n",
            "B) disappointment, because they doubt that she will stay in Threestep for very long.\n",
            "C) embarrassment, because they imagine that she is superior to them.\n",
            "D) resentment, because they feel that she is minimizing their discomfort.\n",
            "\n",
            "Respond with ONLY the letter and full text of the correct answer.\n",
            "\n",
            "[Ground Truth] D\n",
            "[Prediction] <|begin_of_text|>A) sympathy, because they assume that she is experiencing intense heat for the first time.<|eot_id|>\n",
            "\n",
            "--------------------------------------------------\n",
            "====================================================================================================\n",
            "=== Sample 2 ===\n",
            "[Question]\n",
            "Read the passage and answer the question.\n",
            "\n",
            "### Passage: This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She stepped off the train wearing a\n",
            "pair of thick-soled boots suitable for hiking, a navy\n",
            "Line blue dress, and a little white tam that rode the waves\n",
            "of her red hair at a gravity-defying angle. August was\n",
            "a hellish month to step off the train in Georgia,\n",
            "although it was nothing, she said, compared to the\n",
            "119 degrees that greeted her when she arrived one\n",
            "time in Timbuktu, which, she assured us, was a real\n",
            "place in Africa. I believe her remark irritated some of\n",
            "the people gathered to welcome her on the burned\n",
            "grass alongside the tracks. When folks are sweating\n",
            "through their shorts, they don’t like to hear that this\n",
            "is nothing compared to someplace else. Irritated or\n",
            "not, the majority of those present were inclined to see\n",
            "the arrival of the new schoolteacher in a positive\n",
            "light. Hard times were still upon us in 1938, but, like\n",
            "my momma said, “We weren’t no poorer than we’d\n",
            "ever been,” and the citizens of Threestep were in the\n",
            "mood for a little excitement.\n",
            "   Miss Spivey looked like just the right person to\n",
            "give it to them. She was, by almost anyone’s\n",
            "standards, a woman of the world. She’d gone to\n",
            "boarding schools since she was six years old; she’d\n",
            "studied French in Paris and drama in London; and\n",
            "during what she called a “fruitful intermission” in her\n",
            "formal education, she had traveled extensively in the\n",
            "Near East and Africa with a friend of her\n",
            "grandmother’s, one Janet Miller, who was a medical\n",
            "doctor from Nashville, Tennessee. After her travels\n",
            "with Dr. Miller, Miss Spivey continued her education\n",
            "by attending Barnard College in New York City. She\n",
            "told us all that at school the first day. When my little\n",
            "brother Ralphord asked what did she study at\n",
            "Barnyard College, Miss Spivey explained that\n",
            "Barnard, which she wrote on the blackboard, was the\n",
            "sister school of Columbia University, of which, she\n",
            "expected, we all had heard.\n",
            "    It was there, she told us, in the midst of trying to\n",
            "find her true mission in life, that she wandered one\n",
            "afternoon into a lecture by the famous John Dewey,\n",
            "who was talking about his famous book, Democracy\n",
            "and Education. Professor Dewey was in his seventies\n",
            "by then, Miss Spivey said, but he still liked to chat\n",
            "with students after a lecture—especially female\n",
            "students, she added—sometimes over coffee, and see\n",
            "in their eyes the fire his words could kindle. It was\n",
            "after this lecture and subsequent coffee that Miss\n",
            "Spivey had marched to the Teacher’s College and\n",
            "signed up, all aflame. Two years later, she told a\n",
            "cheery blue-suited woman from the WPA1 that she\n",
            "wanted to bring democracy and education to the\n",
            "poorest, darkest, most remote and forgotten corner\n",
            "of America.\n",
            "    They sent her to Threestep, Georgia.\n",
            "    Miss Spivey paused there for questions, avoiding\n",
            "my brother Ralphord’s eye.\n",
            "    What we really wanted to know about—all\n",
            "twenty-six of us across seven grade levels in the one\n",
            "room—was the pearly white button hanging on a\n",
            "string in front of the blackboard behind the teacher’s\n",
            "desk up front. That button on a string was something\n",
            "new. When Mavis Davis (the only bona fide seventh\n",
            "grader, at age thirteen) asked what it was for, Miss\n",
            "Spivey gave the string a tug, and to our astonishment,\n",
            "the whole world—or at least a wrinkled map of\n",
            "it—unfolded before our eyes. Her predecessor, Miss\n",
            "Chandler, had never once made use of that map,\n",
            "which was older than our fathers, and until that\n",
            "moment, not a one of us knew it was there.\n",
            "    Miss Spivey showed us on the map how she and\n",
            "Dr. Janet Miller had sailed across the Atlantic Ocean\n",
            "and past the Rock of Gibraltar into the\n",
            "Mediterranean Sea. Using the end of a ruler, she\n",
            "gently tapped such places as Morocco and Tunis and\n",
            "Algiers to mark their route along the top of Africa.\n",
            "They spent twenty hours on the train to Baghdad, she\n",
            "said, swathed in veils against the sand that crept in\n",
            "every crack and crevice.\n",
            "    “And can you guess what we saw from the train?”\n",
            "Miss Spivey asked. We could not. “Camels!” she said.\n",
            "“We saw a whole caravan of camels.” She looked\n",
            "around the room, waiting for us to be amazed and\n",
            "delighted at the thought.\n",
            "    We all hung there for a minute, thinking hard,\n",
            "until Mavis Davis spoke up.\n",
            "    “She means like the three kings rode to\n",
            "Bethlehem,” Mavis said, and she folded her hands\n",
            "smugly on her seventh-grade desk in the back of the\n",
            "room.\n",
            "    Miss Spivey made a mistake right then. Instead of\n",
            "beaming upon Mavis the kind of congratulatory\n",
            "smile that old Miss Chandler would have bestowed\n",
            "on her for having enlightened the rest of us, Miss\n",
            "Spivey simply said, “That’s right.”\n",
            "### Question: In the third paragraph, what is the narrator most likely suggesting by describing Miss Spivey as having “wandered” (line 40) in one situation and “marched” (line 49) in another situation?\n",
            "### Choices: A) Dewey, knowing Miss Spivey wasn’t very confident in her ability to teach, instilled in her a sense of determination.\n",
            "B) Talking with Dewey over coffee made Miss Spivey realize how excited she was to teach in the poorest, most remote corner of America.\n",
            "C) After two years spent studying, Miss Spivey was anxious to start teaching and be in charge of her own classroom.\n",
            "D) Miss Spivey’s initial encounter with Dewey’s ideas was somewhat accidental but ultimately motivated her to decisive action.\n",
            "\n",
            "Respond with ONLY the letter and full text of the correct answer.\n",
            "\n",
            "[Ground Truth] D\n",
            "[Prediction] <|begin_of_text|>A) Dewey, knowing Miss Spivey wasn’t very confident in her ability to teach, instilled in her a sense of determination.<|eot_id|>\n",
            "\n",
            "--------------------------------------------------\n",
            "====================================================================================================\n",
            "=== Sample 3 ===\n",
            "[Question]\n",
            "Read the passage and answer the question.\n",
            "\n",
            "### Passage: This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She stepped off the train wearing a\n",
            "pair of thick-soled boots suitable for hiking, a navy\n",
            "Line blue dress, and a little white tam that rode the waves\n",
            "of her red hair at a gravity-defying angle. August was\n",
            "a hellish month to step off the train in Georgia,\n",
            "although it was nothing, she said, compared to the\n",
            "119 degrees that greeted her when she arrived one\n",
            "time in Timbuktu, which, she assured us, was a real\n",
            "place in Africa. I believe her remark irritated some of\n",
            "the people gathered to welcome her on the burned\n",
            "grass alongside the tracks. When folks are sweating\n",
            "through their shorts, they don’t like to hear that this\n",
            "is nothing compared to someplace else. Irritated or\n",
            "not, the majority of those present were inclined to see\n",
            "the arrival of the new schoolteacher in a positive\n",
            "light. Hard times were still upon us in 1938, but, like\n",
            "my momma said, “We weren’t no poorer than we’d\n",
            "ever been,” and the citizens of Threestep were in the\n",
            "mood for a little excitement.\n",
            "   Miss Spivey looked like just the right person to\n",
            "give it to them. She was, by almost anyone’s\n",
            "standards, a woman of the world. She’d gone to\n",
            "boarding schools since she was six years old; she’d\n",
            "studied French in Paris and drama in London; and\n",
            "during what she called a “fruitful intermission” in her\n",
            "formal education, she had traveled extensively in the\n",
            "Near East and Africa with a friend of her\n",
            "grandmother’s, one Janet Miller, who was a medical\n",
            "doctor from Nashville, Tennessee. After her travels\n",
            "with Dr. Miller, Miss Spivey continued her education\n",
            "by attending Barnard College in New York City. She\n",
            "told us all that at school the first day. When my little\n",
            "brother Ralphord asked what did she study at\n",
            "Barnyard College, Miss Spivey explained that\n",
            "Barnard, which she wrote on the blackboard, was the\n",
            "sister school of Columbia University, of which, she\n",
            "expected, we all had heard.\n",
            "    It was there, she told us, in the midst of trying to\n",
            "find her true mission in life, that she wandered one\n",
            "afternoon into a lecture by the famous John Dewey,\n",
            "who was talking about his famous book, Democracy\n",
            "and Education. Professor Dewey was in his seventies\n",
            "by then, Miss Spivey said, but he still liked to chat\n",
            "with students after a lecture—especially female\n",
            "students, she added—sometimes over coffee, and see\n",
            "in their eyes the fire his words could kindle. It was\n",
            "after this lecture and subsequent coffee that Miss\n",
            "Spivey had marched to the Teacher’s College and\n",
            "signed up, all aflame. Two years later, she told a\n",
            "cheery blue-suited woman from the WPA1 that she\n",
            "wanted to bring democracy and education to the\n",
            "poorest, darkest, most remote and forgotten corner\n",
            "of America.\n",
            "    They sent her to Threestep, Georgia.\n",
            "    Miss Spivey paused there for questions, avoiding\n",
            "my brother Ralphord’s eye.\n",
            "    What we really wanted to know about—all\n",
            "twenty-six of us across seven grade levels in the one\n",
            "room—was the pearly white button hanging on a\n",
            "string in front of the blackboard behind the teacher’s\n",
            "desk up front. That button on a string was something\n",
            "new. When Mavis Davis (the only bona fide seventh\n",
            "grader, at age thirteen) asked what it was for, Miss\n",
            "Spivey gave the string a tug, and to our astonishment,\n",
            "the whole world—or at least a wrinkled map of\n",
            "it—unfolded before our eyes. Her predecessor, Miss\n",
            "Chandler, had never once made use of that map,\n",
            "which was older than our fathers, and until that\n",
            "moment, not a one of us knew it was there.\n",
            "    Miss Spivey showed us on the map how she and\n",
            "Dr. Janet Miller had sailed across the Atlantic Ocean\n",
            "and past the Rock of Gibraltar into the\n",
            "Mediterranean Sea. Using the end of a ruler, she\n",
            "gently tapped such places as Morocco and Tunis and\n",
            "Algiers to mark their route along the top of Africa.\n",
            "They spent twenty hours on the train to Baghdad, she\n",
            "said, swathed in veils against the sand that crept in\n",
            "every crack and crevice.\n",
            "    “And can you guess what we saw from the train?”\n",
            "Miss Spivey asked. We could not. “Camels!” she said.\n",
            "“We saw a whole caravan of camels.” She looked\n",
            "around the room, waiting for us to be amazed and\n",
            "delighted at the thought.\n",
            "    We all hung there for a minute, thinking hard,\n",
            "until Mavis Davis spoke up.\n",
            "    “She means like the three kings rode to\n",
            "Bethlehem,” Mavis said, and she folded her hands\n",
            "smugly on her seventh-grade desk in the back of the\n",
            "room.\n",
            "    Miss Spivey made a mistake right then. Instead of\n",
            "beaming upon Mavis the kind of congratulatory\n",
            "smile that old Miss Chandler would have bestowed\n",
            "on her for having enlightened the rest of us, Miss\n",
            "Spivey simply said, “That’s right.”\n",
            "### Question: The narrator of the passage can best be described as\n",
            "### Choices: A) one of Miss Spivey’s former students.\n",
            "B) Miss Spivey’s predecessor.\n",
            "C) an anonymous member of the community.\n",
            "D) Miss Spivey herself.\n",
            "\n",
            "Respond with ONLY the letter and full text of the correct answer.\n",
            "\n",
            "[Ground Truth] A\n",
            "[Prediction] <|begin_of_text|>A) one of Miss Spivey’s former students.<|eot_id|>\n",
            "\n",
            "--------------------------------------------------\n",
            "====================================================================================================\n",
            "=== Sample 4 ===\n",
            "[Question]\n",
            "Read the passage and answer the question.\n",
            "\n",
            "### Passage: This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She stepped off the train wearing a\n",
            "pair of thick-soled boots suitable for hiking, a navy\n",
            "Line blue dress, and a little white tam that rode the waves\n",
            "of her red hair at a gravity-defying angle. August was\n",
            "a hellish month to step off the train in Georgia,\n",
            "although it was nothing, she said, compared to the\n",
            "119 degrees that greeted her when she arrived one\n",
            "time in Timbuktu, which, she assured us, was a real\n",
            "place in Africa. I believe her remark irritated some of\n",
            "the people gathered to welcome her on the burned\n",
            "grass alongside the tracks. When folks are sweating\n",
            "through their shorts, they don’t like to hear that this\n",
            "is nothing compared to someplace else. Irritated or\n",
            "not, the majority of those present were inclined to see\n",
            "the arrival of the new schoolteacher in a positive\n",
            "light. Hard times were still upon us in 1938, but, like\n",
            "my momma said, “We weren’t no poorer than we’d\n",
            "ever been,” and the citizens of Threestep were in the\n",
            "mood for a little excitement.\n",
            "   Miss Spivey looked like just the right person to\n",
            "give it to them. She was, by almost anyone’s\n",
            "standards, a woman of the world. She’d gone to\n",
            "boarding schools since she was six years old; she’d\n",
            "studied French in Paris and drama in London; and\n",
            "during what she called a “fruitful intermission” in her\n",
            "formal education, she had traveled extensively in the\n",
            "Near East and Africa with a friend of her\n",
            "grandmother’s, one Janet Miller, who was a medical\n",
            "doctor from Nashville, Tennessee. After her travels\n",
            "with Dr. Miller, Miss Spivey continued her education\n",
            "by attending Barnard College in New York City. She\n",
            "told us all that at school the first day. When my little\n",
            "brother Ralphord asked what did she study at\n",
            "Barnyard College, Miss Spivey explained that\n",
            "Barnard, which she wrote on the blackboard, was the\n",
            "sister school of Columbia University, of which, she\n",
            "expected, we all had heard.\n",
            "    It was there, she told us, in the midst of trying to\n",
            "find her true mission in life, that she wandered one\n",
            "afternoon into a lecture by the famous John Dewey,\n",
            "who was talking about his famous book, Democracy\n",
            "and Education. Professor Dewey was in his seventies\n",
            "by then, Miss Spivey said, but he still liked to chat\n",
            "with students after a lecture—especially female\n",
            "students, she added—sometimes over coffee, and see\n",
            "in their eyes the fire his words could kindle. It was\n",
            "after this lecture and subsequent coffee that Miss\n",
            "Spivey had marched to the Teacher’s College and\n",
            "signed up, all aflame. Two years later, she told a\n",
            "cheery blue-suited woman from the WPA1 that she\n",
            "wanted to bring democracy and education to the\n",
            "poorest, darkest, most remote and forgotten corner\n",
            "of America.\n",
            "    They sent her to Threestep, Georgia.\n",
            "    Miss Spivey paused there for questions, avoiding\n",
            "my brother Ralphord’s eye.\n",
            "    What we really wanted to know about—all\n",
            "twenty-six of us across seven grade levels in the one\n",
            "room—was the pearly white button hanging on a\n",
            "string in front of the blackboard behind the teacher’s\n",
            "desk up front. That button on a string was something\n",
            "new. When Mavis Davis (the only bona fide seventh\n",
            "grader, at age thirteen) asked what it was for, Miss\n",
            "Spivey gave the string a tug, and to our astonishment,\n",
            "the whole world—or at least a wrinkled map of\n",
            "it—unfolded before our eyes. Her predecessor, Miss\n",
            "Chandler, had never once made use of that map,\n",
            "which was older than our fathers, and until that\n",
            "moment, not a one of us knew it was there.\n",
            "    Miss Spivey showed us on the map how she and\n",
            "Dr. Janet Miller had sailed across the Atlantic Ocean\n",
            "and past the Rock of Gibraltar into the\n",
            "Mediterranean Sea. Using the end of a ruler, she\n",
            "gently tapped such places as Morocco and Tunis and\n",
            "Algiers to mark their route along the top of Africa.\n",
            "They spent twenty hours on the train to Baghdad, she\n",
            "said, swathed in veils against the sand that crept in\n",
            "every crack and crevice.\n",
            "    “And can you guess what we saw from the train?”\n",
            "Miss Spivey asked. We could not. “Camels!” she said.\n",
            "“We saw a whole caravan of camels.” She looked\n",
            "around the room, waiting for us to be amazed and\n",
            "delighted at the thought.\n",
            "    We all hung there for a minute, thinking hard,\n",
            "until Mavis Davis spoke up.\n",
            "    “She means like the three kings rode to\n",
            "Bethlehem,” Mavis said, and she folded her hands\n",
            "smugly on her seventh-grade desk in the back of the\n",
            "room.\n",
            "    Miss Spivey made a mistake right then. Instead of\n",
            "beaming upon Mavis the kind of congratulatory\n",
            "smile that old Miss Chandler would have bestowed\n",
            "on her for having enlightened the rest of us, Miss\n",
            "Spivey simply said, “That’s right.”\n",
            "### Question: In the passage, when Miss Spivey announces that shehad seen camels, the students’ reaction suggests that they are\n",
            "### Choices: A) delighted.\n",
            "B) fascinated.\n",
            "C) baffled.\n",
            "D) worried.\n",
            "\n",
            "Respond with ONLY the letter and full text of the correct answer.\n",
            "\n",
            "[Ground Truth] C\n",
            "[Prediction] <|begin_of_text|>A) delighted.<|eot_id|>\n",
            "\n",
            "--------------------------------------------------\n",
            "====================================================================================================\n",
            "=== Sample 5 ===\n",
            "[Question]\n",
            "Read the passage and answer the question.\n",
            "\n",
            "### Passage: This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She stepped off the train wearing a\n",
            "pair of thick-soled boots suitable for hiking, a navy\n",
            "Line blue dress, and a little white tam that rode the waves\n",
            "of her red hair at a gravity-defying angle. August was\n",
            "a hellish month to step off the train in Georgia,\n",
            "although it was nothing, she said, compared to the\n",
            "119 degrees that greeted her when she arrived one\n",
            "time in Timbuktu, which, she assured us, was a real\n",
            "place in Africa. I believe her remark irritated some of\n",
            "the people gathered to welcome her on the burned\n",
            "grass alongside the tracks. When folks are sweating\n",
            "through their shorts, they don’t like to hear that this\n",
            "is nothing compared to someplace else. Irritated or\n",
            "not, the majority of those present were inclined to see\n",
            "the arrival of the new schoolteacher in a positive\n",
            "light. Hard times were still upon us in 1938, but, like\n",
            "my momma said, “We weren’t no poorer than we’d\n",
            "ever been,” and the citizens of Threestep were in the\n",
            "mood for a little excitement.\n",
            "   Miss Spivey looked like just the right person to\n",
            "give it to them. She was, by almost anyone’s\n",
            "standards, a woman of the world. She’d gone to\n",
            "boarding schools since she was six years old; she’d\n",
            "studied French in Paris and drama in London; and\n",
            "during what she called a “fruitful intermission” in her\n",
            "formal education, she had traveled extensively in the\n",
            "Near East and Africa with a friend of her\n",
            "grandmother’s, one Janet Miller, who was a medical\n",
            "doctor from Nashville, Tennessee. After her travels\n",
            "with Dr. Miller, Miss Spivey continued her education\n",
            "by attending Barnard College in New York City. She\n",
            "told us all that at school the first day. When my little\n",
            "brother Ralphord asked what did she study at\n",
            "Barnyard College, Miss Spivey explained that\n",
            "Barnard, which she wrote on the blackboard, was the\n",
            "sister school of Columbia University, of which, she\n",
            "expected, we all had heard.\n",
            "    It was there, she told us, in the midst of trying to\n",
            "find her true mission in life, that she wandered one\n",
            "afternoon into a lecture by the famous John Dewey,\n",
            "who was talking about his famous book, Democracy\n",
            "and Education. Professor Dewey was in his seventies\n",
            "by then, Miss Spivey said, but he still liked to chat\n",
            "with students after a lecture—especially female\n",
            "students, she added—sometimes over coffee, and see\n",
            "in their eyes the fire his words could kindle. It was\n",
            "after this lecture and subsequent coffee that Miss\n",
            "Spivey had marched to the Teacher’s College and\n",
            "signed up, all aflame. Two years later, she told a\n",
            "cheery blue-suited woman from the WPA1 that she\n",
            "wanted to bring democracy and education to the\n",
            "poorest, darkest, most remote and forgotten corner\n",
            "of America.\n",
            "    They sent her to Threestep, Georgia.\n",
            "    Miss Spivey paused there for questions, avoiding\n",
            "my brother Ralphord’s eye.\n",
            "    What we really wanted to know about—all\n",
            "twenty-six of us across seven grade levels in the one\n",
            "room—was the pearly white button hanging on a\n",
            "string in front of the blackboard behind the teacher’s\n",
            "desk up front. That button on a string was something\n",
            "new. When Mavis Davis (the only bona fide seventh\n",
            "grader, at age thirteen) asked what it was for, Miss\n",
            "Spivey gave the string a tug, and to our astonishment,\n",
            "the whole world—or at least a wrinkled map of\n",
            "it—unfolded before our eyes. Her predecessor, Miss\n",
            "Chandler, had never once made use of that map,\n",
            "which was older than our fathers, and until that\n",
            "moment, not a one of us knew it was there.\n",
            "    Miss Spivey showed us on the map how she and\n",
            "Dr. Janet Miller had sailed across the Atlantic Ocean\n",
            "and past the Rock of Gibraltar into the\n",
            "Mediterranean Sea. Using the end of a ruler, she\n",
            "gently tapped such places as Morocco and Tunis and\n",
            "Algiers to mark their route along the top of Africa.\n",
            "They spent twenty hours on the train to Baghdad, she\n",
            "said, swathed in veils against the sand that crept in\n",
            "every crack and crevice.\n",
            "    “And can you guess what we saw from the train?”\n",
            "Miss Spivey asked. We could not. “Camels!” she said.\n",
            "“We saw a whole caravan of camels.” She looked\n",
            "around the room, waiting for us to be amazed and\n",
            "delighted at the thought.\n",
            "    We all hung there for a minute, thinking hard,\n",
            "until Mavis Davis spoke up.\n",
            "    “She means like the three kings rode to\n",
            "Bethlehem,” Mavis said, and she folded her hands\n",
            "smugly on her seventh-grade desk in the back of the\n",
            "room.\n",
            "    Miss Spivey made a mistake right then. Instead of\n",
            "beaming upon Mavis the kind of congratulatory\n",
            "smile that old Miss Chandler would have bestowed\n",
            "on her for having enlightened the rest of us, Miss\n",
            "Spivey simply said, “That’s right.”\n",
            "### Question: In the passage, Threestep is mainly presented as a\n",
            "### Choices: A) summer retreat for vacationers.\n",
            "B) small rural town.\n",
            "C) town that is home to a prominent university.\n",
            "D) comfortable suburb.\n",
            "\n",
            "Respond with ONLY the letter and full text of the correct answer.\n",
            "\n",
            "[Ground Truth] B\n",
            "[Prediction] <|begin_of_text|>A) summer retreat for vacationers.<|eot_id|>\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Inference loop\n",
        "for i in range(5):\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    input_text = data[\"test\"][\"text\"][i]\n",
        "    true_answer = data[\"test\"][\"answer\"][i]\n",
        "\n",
        "    messages = format_inference_prompt(input_text)\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        messages, add_generation_prompt=True, tokenize=False\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs.input_ids,\n",
        "            attention_mask=inputs.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "\n",
        "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "    if \"<|assistant|>\" in full_output:\n",
        "        response = (\n",
        "            full_output.split(\"<|assistant|>\")[1].replace(\"<|eot_id|>\", \"\").strip()\n",
        "        )\n",
        "    else:\n",
        "        response = full_output.replace(prompt, \"\").strip()\n",
        "\n",
        "    print(f\"=== Sample {i+1} ===\")\n",
        "    print(f\"[Question]\\n{messages[1]['content']}\")\n",
        "    print(f\"\\n[Ground Truth] {true_answer}\")\n",
        "    print(f\"[Prediction] {response}\")\n",
        "    print(\"\\n\" + \"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34Tc-FbfE4Ff"
      },
      "outputs": [],
      "source": [
        "def custom_predict(passage: str, question: str, choices: list):\n",
        "    choices_text = \"\\n\".join(choices)\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": LLAMA3_SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Read the passage and answer the question.\n",
        "\n",
        "### Passage:\n",
        "{passage}\n",
        "\n",
        "### Question:\n",
        "{question}\n",
        "\n",
        "### Choices:\n",
        "{choices_text}\n",
        "\n",
        "Respond with ONLY the letter and full text of the correct answer.\"\"\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        messages, add_generation_prompt=True, tokenize=False\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs.input_ids,\n",
        "            attention_mask=inputs.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "\n",
        "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "    if \"<|assistant|>\" in full_output:\n",
        "        response = (\n",
        "            full_output.split(\"<|assistant|>\")[1].replace(\"<|eot_id|>\", \"\").strip()\n",
        "        )\n",
        "    else:\n",
        "        response = full_output.replace(prompt, \"\").strip()\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "licD12dKP3xT",
        "outputId": "8948f351-a791-4333-82d7-b0129c4ab129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Custom Test Result ===\n",
            "[Prediction] <|begin_of_text|>A) To explain his reluctance to judge others<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "custom_passage = \"\"\"\n",
        "This passage is adapted from F. Scott Fitzgerald, The Great Gatsby.\n",
        "\"In my younger and more vulnerable years my father gave me some advice that I’ve been turning over in my mind ever since. ‘Whenever you feel like criticizing anyone,’ he told me, ‘just remember that all the people in this world haven’t had the advantages that you’ve had.’ He didn’t say any more, but we’ve always been unusually communicative in a reserved way, and I understood that he meant a great deal more than that. In consequence, I’m inclined to reserve all judgments, a habit that has opened up many curious natures to me and also made me the victim of not a few veteran bores.\"\n",
        "\"\"\"\n",
        "\n",
        "custom_question = (\n",
        "    \"What is the primary purpose of the narrator’s recollection of his father’s advice?\"\n",
        ")\n",
        "custom_choices = [\n",
        "    \"A) To explain his reluctance to judge others\",  # A is correct, just test\n",
        "    \"B) To highlight his privileged upbringing\",\n",
        "    \"C) To criticize his father’s moral values\",\n",
        "    \"D) To foreshadow future conflicts in the story\",\n",
        "]\n",
        "\n",
        "prediction = custom_predict(custom_passage, custom_question, custom_choices)\n",
        "print(\"\\n=== Custom Test Result ===\")\n",
        "print(\"[Prediction]\", prediction)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09c07700e8b844ac8e7f3fa39b7fcb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b83a2cd256c04c699539018f70cb5a7a",
              "IPY_MODEL_f442d04ac9f141d79442ff666b3ec9f8",
              "IPY_MODEL_1338635003604ef9a381ae4e90656d13"
            ],
            "layout": "IPY_MODEL_6460f5fa30204966940ab5fefa88089b"
          }
        },
        "103394bacaa74355becf76ec07659918": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1338635003604ef9a381ae4e90656d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_225c8653a2414033a39c5e55f4d287a6",
            "placeholder": "​",
            "style": "IPY_MODEL_7ccd7e29f94247e0ad27ae4d978820c7",
            "value": " 2/2 [00:07&lt;00:00,  3.40s/it]"
          }
        },
        "1a9755a097e943e49024f4044128c423": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2057512d97e7496b9b8014d746361de9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225c8653a2414033a39c5e55f4d287a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25bc7c7d289f46da96ee633c7e2d39e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2db0156ec7904d4db5e2f7768b97dacd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "311621b37f79439088b7abb385217380": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2db0156ec7904d4db5e2f7768b97dacd",
            "placeholder": "​",
            "style": "IPY_MODEL_3d549acaf94d44f6a650a1ce283637ff",
            "value": " 97.3M/97.3M [00:07&lt;00:00, 10.2MB/s]"
          }
        },
        "3d549acaf94d44f6a650a1ce283637ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44d033126bdf4c92848dfa5cfddb1713": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d1d6e49915445bdb823aff50e9f30d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2bc133f01734215b09dd6eb7717b3db",
              "IPY_MODEL_57edd5f5d0124f3580763b85509bdd58",
              "IPY_MODEL_311621b37f79439088b7abb385217380"
            ],
            "layout": "IPY_MODEL_640beb91f1dd4e5f90ce413cb2ae0030"
          }
        },
        "5760a005a564413daf983eb827f7db82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57edd5f5d0124f3580763b85509bdd58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5760a005a564413daf983eb827f7db82",
            "max": 97307544,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c0a460e68534565b2271d196fa5ebb7",
            "value": 97307544
          }
        },
        "5c0a460e68534565b2271d196fa5ebb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "640beb91f1dd4e5f90ce413cb2ae0030": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6460f5fa30204966940ab5fefa88089b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66b48f0fea604a7993254d6f9c6e2f76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72d0f71580d84a12aaba22181398ef40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ccd7e29f94247e0ad27ae4d978820c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7de2d6241c60448d9e8bc8b757d3e0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc94d706de3540c6baf5a62fc4e8b741",
            "placeholder": "​",
            "style": "IPY_MODEL_1a9755a097e943e49024f4044128c423",
            "value": " 24.0/24.0 [00:00&lt;00:00, 2.93kB/s]"
          }
        },
        "8b1ed1dbbbd146e896a643f8ea965377": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb5d90d0e5dc4f4bbcff3f85d57132dd",
              "IPY_MODEL_f84659c158e44214b1b711643ad5bdba",
              "IPY_MODEL_7de2d6241c60448d9e8bc8b757d3e0b4"
            ],
            "layout": "IPY_MODEL_b87f346ed31b4679bcde5219e746d849"
          }
        },
        "a1b83097ae9a47d3a55651b198547829": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4a113278423487cb8618927e3852f6e",
              "IPY_MODEL_ea0b24b47bd748f0beae109ea2f3a95a",
              "IPY_MODEL_e1bb0bf97d4c49b4a3e98a1c191473ea"
            ],
            "layout": "IPY_MODEL_fc9a8aed4be947129487baa24b2af408"
          }
        },
        "aa59ca189a174c1183c389c684eb1630": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab02f88a674846f28d5a8aa70826b0ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab9b72df0fdf49fb8ed8f167b3ea11e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2bc133f01734215b09dd6eb7717b3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b913e29b6fdf4c9b84c4d0b1ce1b1638",
            "placeholder": "​",
            "style": "IPY_MODEL_f35a2ff5ca1147c5b1f3f6bd6a229594",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "b83a2cd256c04c699539018f70cb5a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_103394bacaa74355becf76ec07659918",
            "placeholder": "​",
            "style": "IPY_MODEL_e0b95d0377ab412d8f4969e98fa984ac",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b87f346ed31b4679bcde5219e746d849": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b913e29b6fdf4c9b84c4d0b1ce1b1638": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb5d90d0e5dc4f4bbcff3f85d57132dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab02f88a674846f28d5a8aa70826b0ca",
            "placeholder": "​",
            "style": "IPY_MODEL_72d0f71580d84a12aaba22181398ef40",
            "value": "README.md: 100%"
          }
        },
        "cc94d706de3540c6baf5a62fc4e8b741": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a113278423487cb8618927e3852f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f21ed64b5b9b4a849d20a8f554ee8331",
            "placeholder": "​",
            "style": "IPY_MODEL_f952f3d5b5e444f4b80bfe981a06b234",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e0b95d0377ab412d8f4969e98fa984ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1bb0bf97d4c49b4a3e98a1c191473ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa59ca189a174c1183c389c684eb1630",
            "placeholder": "​",
            "style": "IPY_MODEL_44d033126bdf4c92848dfa5cfddb1713",
            "value": " 2/2 [00:06&lt;00:00,  3.12s/it]"
          }
        },
        "ea0b24b47bd748f0beae109ea2f3a95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25bc7c7d289f46da96ee633c7e2d39e8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab9b72df0fdf49fb8ed8f167b3ea11e5",
            "value": 2
          }
        },
        "eac1a2b08e404fce9e5974e665b73fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f21ed64b5b9b4a849d20a8f554ee8331": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35a2ff5ca1147c5b1f3f6bd6a229594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f442d04ac9f141d79442ff666b3ec9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66b48f0fea604a7993254d6f9c6e2f76",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5ac4102937f4760a229245b0f358569",
            "value": 2
          }
        },
        "f5ac4102937f4760a229245b0f358569": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f84659c158e44214b1b711643ad5bdba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2057512d97e7496b9b8014d746361de9",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eac1a2b08e404fce9e5974e665b73fe6",
            "value": 24
          }
        },
        "f952f3d5b5e444f4b80bfe981a06b234": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc9a8aed4be947129487baa24b2af408": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
